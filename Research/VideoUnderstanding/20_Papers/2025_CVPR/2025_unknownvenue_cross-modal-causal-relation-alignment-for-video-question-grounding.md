---
type: paper
title: "Cross-modal Causal Relation Alignment for Video Question Grounding"
venue: "CVPR"
year: 2025
authors: ["Weixing Chen", "Yang Liu", "Binglin Chen", "Jiandong Su", "Yongsen Zheng", "Liang Lin"]
url: "https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Cross-modal_Causal_Relation_Alignment_for_Video_Question_Grounding_CVPR_2025_paper.pdf"
tasks: ["benchmark", "temporal-grounding", "videoqa"]
methods: ["retrieval"]
datasets: []
metrics: []
trends: []
status: to-read
date_read: ""


---

# Main Contribution (3 lines)
1) **What**: "Cross-modal Causal Relation Alignment for Video Question Grounding"에서 제안하는 비디오 이해 접근을 정리.
2) **Why**: 비디오 QA/추론을 위한 증거 추출 및 추론 구조를 제안.
3) **Impact**: 시간적 근거 측면에서 비디오 이해/평가를 확장.

## Method (<=5 bullets)
- 시간적 근거/정렬을 위한 메커니즘을 다룸.

## Evidence
- Benchmarks:
- Key numbers:
- Key ablations (2):
  -
  -

## Assumptions / Limitations (2 each)
- Assumptions:
  -
- Limitations:
  -

## Failure Modes (3)
-
-
-

## One-liner takeaway
- Cross-modal Causal Relation Alignment for Video Question Grounding은/는 비디오 QA/추론을 위한 증거 추출 및 추론 구조를 목표로 한다.

## Next experiment idea (1)
-
