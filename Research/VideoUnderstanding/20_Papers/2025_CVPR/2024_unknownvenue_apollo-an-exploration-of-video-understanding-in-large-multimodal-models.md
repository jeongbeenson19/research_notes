---
type: paper
title: "Apollo: An Exploration of Video Understanding in Large Multimodal Models"
venue: "CVPR"
year: 2025
authors: ["Orr Zohar", "Xiaohan Wang", "Yann Dubois", "Nikhil Mehta", "Tong Xiao", "Philippe Hansen-Estruch", "Licheng Yu", "Xiaofang Wang", "Felix Juefei-Xu", "Ning Zhang", "Serena Yeung-Levy", "Xide Xia"]
url: "https://openaccess.thecvf.com/content/CVPR2025/papers/Zohar_Apollo__An_Exploration_of_Video_Understanding_in_Large_Multimodal_CVPR_2025_paper.pdf"
tasks: ["benchmark", "long-video"]
methods: ["compression", "retrieval"]
datasets: ["MLVU", "Video-MME"]
metrics: []
trends: []
status: to-read
date_read: ""


---

# Main Contribution (3 lines)
1) **What**: 비디오 이해를 위한 새로운 모델/학습/프롬프트 방법을 제안.
2) **Why**: 비디오 이해 성능을 향상시키는 새로운 모델/학습 전략을 제안.
3) **Impact**: 비디오 이해 문제에 대한 새로운 접근을 제시.

## Method (<=5 bullets)
- 문제 설정에 맞춘 비디오 이해 파이프라인/모델 구성을 제안.

## Evidence
- Benchmarks:
- Key numbers:
- Key ablations (2):
  -
  -

## Assumptions / Limitations (2 each)
- Assumptions:
  -
- Limitations:
  -

## Failure Modes (3)
-
-
-

## One-liner takeaway
- Apollo: An Exploration of Video Understanding in Large Multimodal Models은/는 비디오 이해 성능을 향상시키는 새로운 모델/학습 전략을 목표로 한다.

## Next experiment idea (1)
-
