
### **1. 개요 (Overview)**

[[YOLOv1]]은 "You Only Look Once"의 약자로, 2015년 Joseph Redmon 등이 제안한 객체 탐지 알고리즘이다. 이전의 2-Stage Detector([[R-CNN]] 계열)와 달리, 후보 영역(Region Proposal) 단계와 분류(Classification) 단계를 하나의 통합된 네트워크로 처리하는 **1-Stage Detector**의 시초이다. 객체 탐지를 복잡한 파이프라인이 아닌 단일 회귀(regression) 문제로 재정의함으로써, 극도로 빠른 속도를 달성하여 실시간 객체 탐지의 새로운 지평을 열었다.

---

### **2. 핵심 아이디어 (Core Idea)**

YOLOv1의 핵심은 이미지 전체를 한 번만 바라보고 객체의 종류와 위치를 모두 예측하는 것이다.

1.  **그리드 분할 (Grid Cell Division)**
    -   입력 이미지를 S x S (논문에서는 7x7) 크기의 그리드로 나눈다.
    -   어떤 객체의 중심(center)이 특정 그리드 셀 안에 위치하면, 해당 그리드 셀이 그 객체를 탐지할 책임(responsible)을 진다.

2.  **통합된 예측 (Unified Prediction)**
    -   각 그리드 셀은 **B개의 바운딩 박스(Bounding Box)** 와 각 박스에 대한 **신뢰도 점수(Confidence Score)**, 그리고 **C개의 클래스 확률(Class Probability)** 을 예측한다.
    -   **바운딩 박스 (B개)**: 각 박스는 (x, y, w, h) 4개의 값으로 구성된다.
        -   (x, y): 박스 중심의 좌표. 그리드 셀 내에서의 상대적 위치.
        -   (w, h): 전체 이미지 크기에 대한 박스의 상대적인 너비와 높이.
    -   **신뢰도 점수**: `P(Object) * IOU(pred, truth)`
        -   박스 안에 객체가 존재할 확률과 예측된 박스가 실제 정답(ground-truth)과 얼마나 일치하는지(IOU)를 모두 반영한다.
    -   **클래스 확률**: 각 그리드 셀은 객체가 존재한다는 가정 하에, 그 객체가 어떤 클래스에 속할지에 대한 조건부 확률 `P(Class_i | Object)`을 예측한다.

3.  **최종 출력 텐서: S x S x (B * 5 + C)**
    -   YOLOv1의 모든 예측값은 하나의 텐서로 통합됩니다. 이 텐서의 각 차원이 의미하는 바는 다음과 같습니다. (논문 기준: S=7, B=2, C=20)

    -   **`S x S`**: 이미지를 나눈 그리드의 크기입니다. 각 그리드 셀(총 49개)은 독립적인 예측을 수행합니다.

    -   **`B * 5`**: 각 그리드 셀이 예측하는 **B개**의 바운딩 박스 정보입니다.
        -   하나의 바운딩 박스는 5개의 값으로 구성됩니다:
            1.  `x`: 바운딩 박스 중심의 x좌표
            2.  `y`: 바운딩 박스 중심의 y좌표
            3.  `w`: 바운딩 박스의 너비
            4.  `h`: 바운딩 박스의 높이
            5.  `Confidence Score`: 이 박스가 객체를 포함하고 있다는 신뢰도 점수
        -   따라서 B개의 박스를 예측하기 위해 `B * 5`개의 값이 필요합니다. (논문에서는 B=2)

    -   **`C`**: 각 그리드 셀이 예측하는 **C개**의 클래스에 대한 확률 정보입니다.
        -   중요한 점은, 그리드 셀당 클래스 확률은 **한 세트만** 예측된다는 것입니다. 즉, B개의 바운딩 박스는 이 클래스 확률을 공유합니다.
        -   이는 "해당 그리드 셀에 객체가 존재한다면, 그 객체가 각 클래스일 조건부 확률" `P(Class_i | Object)`을 의미합니다. (논문에서는 C=20)

    -   **결합**: 결과적으로, `S x S`개의 각 셀은 `(B * 5 + C)`개의 예측값을 가지므로, 최종 출력 텐서의 크기는 **S x S x (B * 5 + C)** 가 됩니다.
        -   (예: 7 x 7 x (2*5 + 20) = 7 x 7 x 30)

---

### 3. 네트워크 아키텍처 (Network Architecture)

-   GoogLeNet에서 영감을 받은 커스텀 네트워크를 사용한다.
-   24개의 컨볼루션 레이어와 2개의 완전 연결(fully connected) 레이어로 구성된다.
-   컨볼루션 레이어는 이미지로부터 특징을 추출하고, 완전 연결 레이어는 최종적으로 바운딩 박스 좌표와 클래스 확률을 예측한다.
-   **Fast YOLO**라는 경량화 버전은 9개의 컨볼루션 레이어만 사용하여 더 빠른 속도를 제공한다.

---

### 4. 학습 (Training)

YOLOv1의 학습은 두 단계로 이루어지며, 전체 탐지 문제를 하나의 회귀 문제로 취급하는 독특한 손실 함수(Loss Function)를 통해 최적화됩니다.

#### **4.1. 사전 학습 (Pre-training)**
- **분류 모델 학습**: 먼저 ImageNet 1000-class 데이터셋을 사용하여 네트워크의 컨볼루션 레이어(24개 중 20개)를 사전 학습시킵니다. 이는 강력한 시각적 특징 추출 능력을 네트워크에 부여합니다.

#### **4.2. 탐지 모델 학습 (Detection Training)**
- **네트워크 변환**: 사전 학습된 컨볼루션 레이어 위에 4개의 컨볼루션 레이어와 2개의 완전 연결 레이어를 추가하여 전체 탐지 네트워크를 구성합니다.
- **손실 함수 (Loss Function)**: YOLOv1의 손실 함수는 **좌표 예측(Localization)**, **객체 존재 신뢰도(Confidence)**, **클래스 예측(Classification)** 이라는 세 가지 요소를 모두 포함하는 **다중 파트(multi-part) 손실 함수**입니다. 모든 요소는 SSE(Sum-Squared Error)를 기반으로 계산됩니다.

1.  **좌표 손실 (Localization Loss)**
    -   객체가 존재한다고 판단되는 그리드 셀에서, 예측된 바운딩 박스(`x, y, w, h`)와 실제 정답 박스 간의 오차를 계산합니다.
    -   **작은 박스의 오차에 더 큰 가중치**를 주기 위해, 너비(`w`)와 높이(`h`)에 제곱근(square root)을 취한 후 오차를 계산합니다. 이는 큰 박스에서 약간의 오차는 덜 중요하지만, 작은 박스에서는 치명적일 수 있다는 점을 반영한 것입니다.
    -   이 손실은 `λ_coord` (논문에서는 5)라는 가중치가 곱해져 다른 손실보다 더 중요하게 다루어집니다.

2.  **신뢰도 손실 (Confidence Loss)**
    -   **객체가 있는 경우**: 예측된 신뢰도 점수가 실제 IOU 값(1에 가까움)에 가까워지도록 학습합니다.
    -   **객체가 없는 경우**: 예측된 신뢰도 점수가 0에 가까워지도록 학습합니다.
    -   대부분의 그리드 셀에는 객체가 없으므로, '객체 없음' 손실이 전체 손실을 지배하는 것을 막기 위해 `λ_noobj` (논문에서는 0.5)라는 가중치를 곱해 손실의 영향력을 줄입니다.

3.  **분류 손실 (Classification Loss)**
    -   객체가 존재하는 그리드 셀에 대해서만, 예측된 클래스 확률과 실제 클래스(one-hot 인코딩) 간의 오차를 계산합니다.

이 세 가지 손실을 모두 더하여 최종 손실을 구성하고, 이를 최소화하는 방향으로 네트워크의 모든 가중치를 한 번에 (end-to-end) 업데이트합니다.

---

### 5. 장점 (Advantages)

1.  **매우 빠른 속도**: 기본 모델이 45 FPS, Fast YOLO는 155 FPS를 달성하여 실시간 처리가 가능하다.
2.  **전역적 문맥 이해**: 이미지 전체를 한 번에 처리하므로, 객체와 배경을 포함한 전역적인 문맥(global context)을 학습한다. 이는 [[Fast R-CNN]]과 같은 슬라이딩 윈도우 방식보다 배경 오류(background error)가 적은 이유가 된다.
3.  **일반화 성능**: 실제 이미지로 학습한 후 예술 작품 이미지에서도 좋은 탐지 성능을 보여주는 등, 일반화 능력이 뛰어나다.

---

### 6. 단점 (Limitations)

1.  **낮은 정확도**: 속도는 빠르지만, [[Faster R-CNN]]과 같은 2-Stage detector에 비해 정확도, 특히 위치 정밀도(localization accuracy)가 떨어진다.
2.  **작은 객체 탐지 어려움**: 하나의 그리드 셀이 제한된 수(2개)의 박스만 예측하고 하나의 클래스만 가질 수 있어, 새 떼와 같이 작은 객체들이 몰려있는 경우 탐지가 어렵다.
3.  **새로운 형태/비율 객체 취약**: 학습 데이터에서 보지 못했던 새로운 종횡비(aspect ratio)나 형태를 가진 객체에 대한 예측 성능이 저하된다.

이러한 한계들은 후속 버전인 [[YOLOv2]]와 [[YOLOv3]]에서 점차 개선된다.
