---
tags: [concept, math, deep-learning]
aliases: [텐서]
---

텐서(Tensor)는 스칼라, 벡터, 행렬의 개념을 더 높은 차원으로 일반화한 수학적 객체이자, 현대 딥러닝 프레임워크에서 데이터를 표현하는 가장 기본적인 단위입니다. 딥러닝에서는 다차원 배열(multi-dimensional array)의 형태로 텐서를 이해하는 것이 가장 직관적입니다.

---

### **1. 텐서의 개념: 차원(Dimension)과 랭크(Rank)**

텐서는 '랭크(Rank)' 또는 '차수(Order)'라는 개념으로 차원을 표현합니다. 이는 텐서의 데이터를 표현하는 데 필요한 축(axis) 또는 인덱스(index)의 개수를 의미합니다.

-   **랭크 0 텐서 (Scalar)**
    -   하나의 숫자 값을 가지는 데이터입니다.
    -   예: `5`, `-2.3`
    -   형상(Shape): `[]`

-   **랭크 1 텐서 (Vector)**
    -   숫자의 1차원 배열입니다.
    -   예: `[1, 2, 3]`
    -   형상(Shape): `[3]`

-   **랭크 2 텐서 (Matrix)**
    -   숫자의 2차원 배열(행과 열)입니다.
    -   예: `[[1, 2], [3, 4]]`
    -   형상(Shape): `[2, 2]`

-   **랭크 3 텐서**
    -   숫자의 3차원 배열입니다. 여러 개의 행렬이 쌓여있는 형태로 볼 수 있습니다.
    -   예: `[[[1, 2], [3, 4]], [[5, 6], [7, 8]]]`
    -   형상(Shape): `[2, 2, 2]`

-   **랭크 n 텐서**
    -   n개의 축을 가지는 n차원 배열입니다.

> **참고**: 수학(특히 물리학)에서 텐서는 좌표계가 변환될 때 특정 규칙에 따라 그 성분이 함께 변환되는 다중 선형 사상(multilinear map)으로 더 엄밀하게 정의됩니다. 하지만 딥러닝 분야에서는 주로 다차원 배열이라는 실용적인 관점에서 접근합니다.

---

### **2. 딥러닝에서의 텐서의 역할**

딥러닝의 모든 연산은 텐서를 입력으로 받아 텐서를 출력하는 형태로 이루어집니다. 텐서는 다양한 유형의 데이터를 표현하는 표준화된 방법을 제공합니다.

-   **이미지 데이터 (Image Data)**
    -   컬러 이미지는 보통 **랭크 4 텐서**로 표현됩니다.
    -   형상: `(Batch, Height, Width, Channels)`
        -   `Batch`: 한 번에 처리할 이미지의 개수
        -   `Height`: 이미지의 세로 픽셀 수
        -   `Width`: 이미지의 가로 픽셀 수
        -   `Channels`: 색상 채널 (예: RGB는 3, 흑백은 1)
    -   예: 64x64 크기의 컬러 이미지 32장 묶음 → `(32, 64, 64, 3)`

-   **자연어 데이터 (Text Data)**
    -   텍스트는 보통 단어 또는 토큰을 정수로 변환한 후, 이를 텐서로 표현합니다.
    -   문장들의 배치는 주로 **랭크 2 텐서**로 표현됩니다.
    -   형상: `(Batch, Sequence_Length)`
        -   `Batch`: 문장의 개수
        -   `Sequence_Length`: 각 문장을 구성하는 단어/토큰의 최대 개수
    -   예: 최대 20개 단어로 이루어진 문장 16개 묶음 → `(16, 20)`

-   **모델 파라미터 (Model Parameters)**
    -   신경망의 가중치(weights)와 편향(biases) 역시 텐서로 저장됩니다.
    -   예: 완전 연결 계층(fully connected layer)의 가중치는 랭크 2 텐서(행렬)입니다.

---

### **3. 딥러닝 프레임워크에서의 텐서**

[[PyTorch]], TensorFlow와 같은 딥러닝 프레임워크는 텐서 연산을 위한 강력한 기능을 제공합니다.

-   **GPU 가속**: 프레임워크의 텐서는 NumPy의 `ndarray`와 유사하지만, GPU 상에서 병렬 연산을 수행할 수 있어 대규모 행렬 곱셈 등이 매우 빠릅니다. 이는 딥러닝 모델 학습 시간을 획기적으로 단축시키는 핵심 요소입니다.
-   **자동 미분 (Automatic Differentiation)**: 텐서에 대한 모든 연산 기록을 추적하여, 역전파 과정에서 필요한 그래디언트를 자동으로 계산해줍니다. (예: PyTorch의 `autograd`)

---

### **4. 텐서의 데이터 타입 (Data Types)**

텐서는 다차원 배열일 뿐만 아니라, 내부에 담기는 데이터의 종류(type)를 지정할 수 있습니다. 이를 `dtype`이라 부르며, 연산의 효율성과 정확성에 큰 영향을 미칩니다. 딥러닝에서 가장 흔하게 사용되는 두 가지 데이터 타입은 다음과 같습니다.

-   **Float Tensor (`torch.float32` 또는 `torch.FloatTensor`)**
    -   32비트 부동소수점 숫자를 저장하는 텐서입니다.
    -   딥러닝 모델의 **가중치(weights), 편향(biases)** 과 같은 파라미터들은 대부분 Float Tensor입니다.
    -   이미지 픽셀 값, 정규화된 데이터 등 연속적인 값을 가지는 **모델의 입력 데이터**에 주로 사용됩니다.
    -   가장 중요한 특징은 **그래디언트(gradient) 계산이 가능**하다는 점입니다. 자동 미분 엔진은 부동소수점 연산에 대해서만 미분을 수행하므로, 학습되어야 할 모든 값들은 Float Tensor 형태여야 합니다.

-   **Long Tensor (`torch.int64` 또는 `torch.LongTensor`)**
    -   64비트 정수를 저장하는 텐서입니다.
    -   그래디언트 계산이 필요 없는 정수형 데이터를 다룰 때 사용됩니다.
    -   가장 대표적인 용도는 분류(classification) 문제에서의 **레이블(label) 또는 타겟(target)** 입니다. 예를 들어, 10개 클래스 분류 문제의 정답은 0부터 9까지의 정수로 표현되며, 이는 Long Tensor에 저장됩니다.
    -   임베딩 룩업(embedding lookup)을 위한 인덱스(index)나 특정 위치를 가리키는 용도로도 널리 사용됩니다.

결론적으로, 텐서는 복잡하고 다양한 데이터를 컴퓨터가 처리할 수 있는 표준화된 숫자 배열 형태로 변환하고, GPU를 통해 이러한 데이터를 효율적으로 연산하기 위한 딥러닝의 필수적인 구성 요소입니다.
