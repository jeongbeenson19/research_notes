# Support Vector Machines (SVM)

#MachineLearning #Classification #Regression

---

## 1. 개요

**Support Vector Machines (SVM)**은 분류(classification)와 회귀(regression) 분석에 사용되는 강력한 지도 학습(supervised learning) 모델입니다. 특히 분류 문제에서 뛰어난 성능을 보이며, 복잡한 데이터셋에서도 효과적으로 작동합니다.

SVM의 핵심 아이디어는 데이터를 분류하는 **최적의 결정 경계(optimal hyperplane)** 를 찾는 것입니다. 이 결정 경계는 각 클래스의 가장 가까운 데이터 포인트(서포트 벡터, Support Vectors)로부터 가장 멀리 떨어져 있는 경계입니다. 즉, **마진(margin)을 최대화**하는 것이 목표입니다.

---

## 2. 핵심 개념

### 2.1. 결정 경계 (Hyperplane)

- $N$차원 공간에서 데이터를 분류하는 경계면입니다.
- 2차원에서는 선(line), 3차원에서는 평면(plane)이 됩니다.

### 2.2. 서포트 벡터 (Support Vectors)

- 결정 경계에 가장 가까이 위치한 데이터 포인트들입니다.
- 이 서포트 벡터들만이 결정 경계를 정의하는 데 사용됩니다. 나머지 데이터 포인트들은 결정 경계에 영향을 주지 않습니다.

### 2.3. 마진 (Margin)

- 결정 경계와 가장 가까운 서포트 벡터 사이의 거리입니다.
- SVM은 이 마진을 최대화하는 결정 경계를 찾습니다. 마진이 클수록 모델의 일반화 성능이 좋다고 간주됩니다.

---

## 3. 선형 SVM과 비선형 SVM

### 3.1. 선형 SVM (Linear SVM)

- 데이터가 선형적으로 분리 가능한 경우에 사용됩니다.
- 하나의 직선 또는 평면으로 두 클래스를 완벽하게 나눌 수 있습니다.

### 3.2. 비선형 SVM (Non-linear SVM)

- 데이터가 선형적으로 분리 불가능한 경우에 사용됩니다.
- **커널 트릭(Kernel Trick)** 이라는 기법을 사용하여 데이터를 고차원 공간으로 매핑합니다. 고차원 공간에서는 비선형적으로 분리 불가능했던 데이터가 선형적으로 분리 가능해질 수 있습니다.
- **주요 커널 함수:**
    - **다항식 커널 (Polynomial Kernel)**
    - **가우시안 RBF 커널 (Radial Basis Function Kernel):** 가장 널리 사용되며, 무한 차원으로 데이터를 매핑하는 효과가 있습니다.
    - **시그모이드 커널 (Sigmoid Kernel)**

---

## 4. 장점 및 단점

### 장점
- **높은 일반화 성능:** 마진을 최대화하여 과적합(overfitting) 위험을 줄이고 새로운 데이터에 대한 예측 성능이 뛰어납니다.
- **효과적인 고차원 데이터 처리:** 커널 트릭을 통해 고차원 데이터에서도 잘 작동합니다.
- **적은 데이터셋에서도 강점:** 서포트 벡터에만 의존하므로 데이터 포인트가 적어도 비교적 안정적인 성능을 보입니다.

### 단점
- **학습 속도:** 데이터셋의 크기가 매우 클 경우 학습 시간이 오래 걸릴 수 있습니다.
- **커널 함수 및 파라미터 선택:** 최적의 커널 함수와 하이퍼파라미터(C, gamma 등)를 선택하는 것이 중요하며, 이는 경험과 실험에 의존합니다.
- **결과 해석의 어려움:** 결정 경계가 복잡해질수록 모델의 결과를 직관적으로 해석하기 어렵습니다.

---

## 5. 활용 분야

- **텍스트 분류:** 스팸 메일 분류, 감성 분석
- **이미지 분류:** 얼굴 인식, 객체 인식
- **생물 정보학:** 단백질 분류, 유전자 발현 분석
- **필기체 숫자 인식**

SVM은 딥러닝이 등장하기 전까지 분류 문제에서 가장 강력한 알고리즘 중 하나였으며, 지금도 비교적 작은 데이터셋이나 고차원 데이터셋에서 좋은 성능을 보이는 중요한 머신러닝 기법입니다.
