
## âœ… 1. DropConnectë€?

**DropConnect**ëŠ” **ì‹ ê²½ë§ì˜ ê°€ì¤‘ì¹˜(weight)** ì— **ëœë¤í•œ ë§ˆìŠ¤í‚¹(masking)** ì„ ì ìš©í•˜ì—¬ **ê³¼ì í•©ì„ ë°©ì§€í•˜ëŠ” ì •ê·œí™” ê¸°ë²•**ì…ë‹ˆë‹¤.

> ğŸ” **í•µì‹¬ ì•„ì´ë””ì–´**: Dropoutì´ ë‰´ëŸ°ì„ ëœë¤í•˜ê²Œ ì œê±°í•˜ëŠ” ê²ƒì´ë¼ë©´, **DropConnectëŠ” ë‰´ëŸ° ê°„ì˜ ì—°ê²°ì„ (=ê°€ì¤‘ì¹˜)ì„ ëœë¤í•˜ê²Œ ì œê±°**í•©ë‹ˆë‹¤.

---

## âœ… 2. Dropout vs DropConnect: ë¹„êµ

| í•­ëª©       | **Dropout**        | **DropConnect**                      |
| -------- | ------------------ | ------------------------------------ |
| ë§ˆìŠ¤í‚¹ ëŒ€ìƒ   | ë‰´ëŸ°ì˜ ì¶œë ¥ê°’            | **ê°€ì¤‘ì¹˜ (weight matrix)**              |
| ë™ì‘ ë°©ì‹    | ì¶œë ¥ê°’ì„ í™•ë¥ ì ìœ¼ë¡œ 0ìœ¼ë¡œ ë§Œë“¦  | weightë¥¼ í™•ë¥ ì ìœ¼ë¡œ 0ìœ¼ë¡œ ë§Œë“¦                 |
| ìˆ˜ì‹ ì ìš© ìœ„ì¹˜ | í™œì„±ê°’ $a = f(Wx)$ ì´í›„ | ì„ í˜•ë³€í™˜ $z = Wx$ ê³„ì‚° ì‹œ $W$ì— ì ìš©           |
| ê³„ì‚° ë¹„ìš©    | ìƒëŒ€ì ìœ¼ë¡œ ì ìŒ           | ë” í¼ (Weight-level mask í•„ìš”)           |
| ì¼ë°˜í™” íš¨ê³¼   | ìˆìŒ                 | ë” ê°•ë ¥í•  ìˆ˜ ìˆìŒ (ì‹¤ì œë¡œ ë” regularizationì´ ë¨) |

---

## âœ… 3. ìˆ˜í•™ì  ì •ì˜

ì‹ ê²½ë§ì˜ í•œ ì¸µì—ì„œ ì„ í˜• ë³€í™˜ì€ ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„ë©ë‹ˆë‹¤:

$$
z = W x$
$$

ì—¬ê¸°ì„œ DropConnectëŠ” weight matrix $W$ì— ëŒ€í•´ element-wise binary mask $M$ì„ ê³±í•´ ë‹¤ìŒê³¼ ê°™ì´ ìˆ˜ì •í•©ë‹ˆë‹¤:

$$
z = (W \odot M) x
$$
- $M_{ij} \sim \text{Bernoulli}(p)$: ê° weight $W_{ij}$ì— ëŒ€í•´ í™•ë¥  $p$ë¡œ ìœ ì§€, $1 - p$ë¡œ ì œê±°
    
- $\odot$: element-wise ê³±
    

ì¦‰, DropConnectëŠ” í•™ìŠµ ê³¼ì •ì—ì„œ **ê° forward passë§ˆë‹¤ ê°€ì¤‘ì¹˜ì˜ ì¼ë¶€ë¥¼ 0ìœ¼ë¡œ ë§Œë“¤ì–´ ë„¤íŠ¸ì›Œí¬ë¥¼ ë¬´ì‘ìœ„ë¡œ í¬ì†Œí•˜ê²Œ** ë§Œë“­ë‹ˆë‹¤.

---

## âœ… 4. ì§ê´€ì  ì´í•´

- **Dropout**ì€ "ì´ ë‰´ëŸ°ì€ ì•„ì˜ˆ ì‘ë™í•˜ì§€ ë§ˆ!"
    
- **DropConnect**ëŠ” "ì´ ë‰´ëŸ°ì€ ì‘ë™ì€ í•˜ë˜, **ì—°ê²°ì„  ì¼ë¶€ëŠ” ëŠì–´ë†“ì**."
    

ì´ë¡œ ì¸í•´ DropConnectëŠ” í›¨ì”¬ **ì„¸ë°€í•˜ê²Œ êµ¬ì¡°ë¥¼ ë¬´ì‘ìœ„í™”**í•©ë‹ˆë‹¤.

---

## âœ… 5. ì˜ˆì‹œ: Fully Connected Layerì— ì ìš©

ê¸°ì¡´ FC layer:

$$
z_i = \sum_j W_{ij} x_j
$$

DropConnect ì ìš© í›„:

$$
z_i = \sum_j (W_{ij} \cdot M_{ij}) x_j
$$

ì´ ë•Œ $M_{ij} \in \{0, 1\}$ëŠ” ë§¤ í•™ìŠµ ë°°ì¹˜ì—ì„œ ëœë¤í•˜ê²Œ ì¬ìƒ˜í”Œë©ë‹ˆë‹¤.

---

## âœ… 6. ì¥ì 

|ì¥ì |ì„¤ëª…|
|---|---|
|âœ… ë” ê°•ë ¥í•œ ì •ê·œí™”|Dropoutë³´ë‹¤ ë” ë†’ì€ ì¼ë°˜í™” ì„±ëŠ¥ ê°€ëŠ¥|
|âœ… íŒŒë¼ë¯¸í„° ë‹¨ìœ„ì˜ ì œì–´|ë‰´ëŸ° ì „ì²´ê°€ ì•„ë‹Œ ê°€ì¤‘ì¹˜ ë‹¨ìœ„ì—ì„œì˜ sparsity|
|âœ… ë‹¤ë¥¸ ì •ê·œí™”ì™€ ë³‘í–‰ ê°€ëŠ¥|BatchNorm, MaxNormê³¼ ë³‘í–‰ ì‚¬ìš© ê°€ëŠ¥|

---

## âœ… 7. ë‹¨ì 

|ë‹¨ì |ì„¤ëª…|
|---|---|
|âŒ ê³„ì‚° ë¹„ìš© ì¦ê°€|ê° weightì— ëŒ€í•´ mask ì—°ì‚° í•„ìš”|
|âŒ í•™ìŠµ ì†ë„ ëŠë¦¼|Dropoutë³´ë‹¤ êµ¬í˜„ì´ ë³µì¡í•˜ê³  ëŠë¦´ ìˆ˜ ìˆìŒ|
|âŒ Conv Layerì— ë°”ë¡œ ì ìš©ì€ ì–´ë ¤ì›€|CNNì—ì„œëŠ” weight sharing êµ¬ì¡° ë•Œë¬¸ì— ë³€í˜• í•„ìš”|

---

## âœ… 8. DropConnectë¥¼ ì œì•ˆí•œ ë…¼ë¬¸

**Wan et al. (2013)**

- ë…¼ë¬¸ ì œëª©: _Regularization of Neural Networks using DropConnect_
    
- ë°œí‘œ: ICML 2013
    
- ë§í¬: [https://proceedings.mlr.press/v28/wan13.html](https://proceedings.mlr.press/v28/wan13.html)
    

> ğŸ” ê²°ê³¼: DropConnectëŠ” MNISTì—ì„œ Dropoutë³´ë‹¤ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì˜€ê³ , ë‹¤ì–‘í•œ ì‹ ê²½ë§ êµ¬ì¡°ì—ì„œë„ regularization íš¨ê³¼ê°€ ì…ì¦ë¨.

---

## âœ… 9. í˜„ëŒ€ì  í™œìš© ì˜ˆì‹œ: **EfficientNet â†’ DropConnectì˜ ë³€í˜• ì‚¬ìš©**

- EfficientNetì—ì„œëŠ” **Stochastic Depth (DropPath)**ë¼ëŠ” ë³€í˜• ê¸°ë²•ì„ ì‚¬ìš©í–ˆëŠ”ë°,  
    ì´ëŠ” Residual ì—°ê²°ì—ì„œ **ë ˆì´ì–´ ì „ì²´ë¥¼ ë“œë**í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.
    
- ì´ëŠ” DropConnectì˜ ì•„ì´ë””ì–´ì™€ ìœ ì‚¬í•˜ê²Œ **ê²½ë¡œë¥¼ ëœë¤í•˜ê²Œ ì¤„ì—¬ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë†’ì´ëŠ” ê¸°ë²•**ì…ë‹ˆë‹¤.
    

---

## âœ… 10. DropConnect êµ¬í˜„ ì˜ˆì‹œ (PyTorch)

```python
class DropConnectLinear(nn.Linear):
    def __init__(self, in_features, out_features, bias=True, drop_prob=0.5):
        super().__init__(in_features, out_features, bias)
        self.drop_prob = drop_prob

    def forward(self, x):
        if self.training:
            # DropConnect mask on weight
            mask = torch.bernoulli(torch.ones_like(self.weight) * (1 - self.drop_prob))
            weight = self.weight * mask
        else:
            weight = self.weight * (1 - self.drop_prob)  # expectation during inference
        return F.linear(x, weight, self.bias)
```

---

## âœ… 11. ìš”ì•½

|í•­ëª©|ë‚´ìš©|
|---|---|
|ì •ì˜|ë‰´ëŸ° ê°„ ì—°ê²°ì„ (ê°€ì¤‘ì¹˜)ë¥¼ ë¬´ì‘ìœ„ë¡œ ì œê±°í•˜ëŠ” ì •ê·œí™” ê¸°ë²•|
|ëª©ì |ê³¼ì í•© ë°©ì§€ ë° ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ|
|Dropoutê³¼ ì°¨ì´|Dropoutì€ ë‰´ëŸ° ì œê±°, DropConnectëŠ” ì—°ê²° ì œê±°|
|í•œê³„|ê³„ì‚°ëŸ‰ ì¦ê°€, Conv êµ¬ì¡°ì— ì§ì ‘ ì ìš© ì–´ë ¤ì›€|
|í™œìš©|EfficientNet(Stochastic Depth), RNN/LSTM ì¼ë°˜í™” ë“±|

---
