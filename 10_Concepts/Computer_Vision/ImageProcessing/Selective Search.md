
**Selective Search**는 **객체 탐지(Object Detection)** 에서 **후보 영역(Region Proposals)** 을 생성하기 위해 사용되는 알고리즘입니다. 즉, 이미지 내에서 **"어디에 객체가 있을 수 있는가"** 를 빠르게 추려내는 방법입니다.

#### 참고자료:
https://blog.naver.com/laonple/220925179894
---

### ✅ **주요 아이디어**

1. **저수준(segmentation) 정보 활용**
    
    - 먼저 이미지의 색상, 질감, 크기 등의 저수준 특징을 이용해 **슈퍼픽셀([[Superpixels]])** 단위로 과분할(over-segmentation)을 수행합니다.
        
2. **유사한 영역 병합**
    
    - 인접한 영역들 간의 **유사도(색상, 질감, 크기, 공간적 인접성)** 를 계산하고, 가장 유사한 영역끼리 순차적으로 병합합니다.
        
3. **다양한 스케일 확보**
    
    - 병합 과정을 여러 스케일에서 반복해, 작은 물체부터 큰 물체까지 다양한 크기의 후보 영역을 생성합니다.
        
4. **후보 영역 출력**
    
    - 병합된 모든 단계에서 생성된 영역들을 **Region Proposal**로 사용합니다.
        

---

### ✅ **왜 필요한가?**

- 전통적인 R-CNN과 같은 객체 탐지 모델은 이미지의 모든 위치와 스케일을 **슬라이딩 윈도우**로 탐색하면 연산량이 너무 많습니다.
    
- Selective Search는 이 연산을 크게 줄여주며, **수천 개 정도의 후보 영역만 평가하면 되도록** 효율적으로 필터링해 줍니다.
    

---

### ✅ **장단점**

✔ **장점**

- 비교적 간단하며, 학습이 필요 없는 비지도 방식
    
- 다양한 스케일의 객체를 포괄 가능
    

✘ **단점**

- 느립니다. (특히 고해상도 이미지에서 수 초 이상 걸릴 수 있음)
    
- 후보 영역이 많아서 중복이 발생하고, 정밀도가 떨어질 수 있음 → 이후 **Region Proposal Network(RPN, Faster R-CNN)** 으로 대체됨.
    

---

# **Selective Search의 구체적인 연산 과정**
---

## ✅ **1. 과분할 (Initial Segmentation)**

- **입력:** RGB 이미지
    
- **과정:**
    
    1. **[[Felzenszwalb & Huttenlocher’s graph-based segmentation]]** 알고리즘을 주로 사용.
        
        - 각 픽셀을 노드로 간주하고, 인접 픽셀 간의 색상/밝기 차이를 엣지 가중치로 표현.
            
        - 비슷한 픽셀끼리 묶어 **슈퍼픽셀(Superpixels)** 로 분할.
            
    2. 보통 수백~수천 개의 작은 영역으로 분할됨.
        

---

## ✅ **2. 영역 유사도 계산 (Region Similarity Calculation)**

모든 **인접한 영역 쌍**에 대해 유사도를 계산합니다. Selective Search에서 유사도는 다음 **4가지 항목**의 합으로 정의됩니다.

1. **색상 유사도 $S_{\text{color}}$**
    
    - 각 영역의 색상 히스토그램 $H_c$ (보통 25~32 bin, RGB 혹은 HSV 사용)을 계산.
        
    - 두 영역의 유사도는 **히스토그램 교차(Histogram Intersection)** 로 정의:
        
        $$S_{\text{color}}(A, B) = \sum_{i} \min(H_c^A(i), H_c^B(i))$$
2. **질감 유사도 $S_{\text{texture}}$**
    
    - 질감 히스토그램은 **Gaussian derivatives** (예: Gabor filter)로 계산.
        
    - 유사도 역시 히스토그램 교차 방식:
        
        $$S_{\text{texture}}(A, B) = \sum_{i} \min(H_t^A(i), H_t^B(i))$$
3. **크기 유사도 $S_{\text{size}}$**
    
    - 두 영역이 너무 큰 차이를 보이지 않도록 작은 영역끼리 병합을 선호.
        
        $$S_{\text{size}}(A, B) = 1 - \frac{\text{size}(A) + \text{size}(B)}{\text{size}(\text{image})}$$
4. **공간적 인접성 유사도 $S_{\text{fill}}$**
    
    - 두 영역이 가까이 붙어 있을수록(빈 공간이 적을수록) 병합을 선호.
        
        $$S_{\text{fill}}(A, B) = 1 - \frac{\text{bbox}(A \cup B) - \text{size}(A) - \text{size}(B)}{\text{size}(\text{image})}$$

**최종 유사도**는 위 4가지를 합산한 값:

$$S(A, B) = S_{\text{color}} + S_{\text{texture}} + S_{\text{size}} + S_{\text{fill}}$$

---

## ✅ **3. 영역 병합 (Region Merging)**

1. **가장 유사도가 높은 두 영역 쌍을 선택**
    
2. 두 영역을 병합하여 새로운 영역 생성
    
3. 병합된 새로운 영역에 대해 **이웃하는 영역과 유사도 재계산**
    
4. 이 과정을 **영역이 하나만 남을 때까지 반복**
    

---

## ✅ **4. 후보 영역(Region Proposals) 생성**

- 병합이 진행되는 **모든 단계에서의 모든 영역**을 후보로 사용.
    
- 즉, **초기 작은 슈퍼픽셀 → 점점 병합된 큰 영역**까지 포함.
    
- 보통 한 이미지당 **2,000~3,000개의 후보 영역**이 생성됨.
    

---

## ✅ **5. 최종 출력**

- 각 후보 영역에 대해 **바운딩 박스 좌표**를 저장하고, 이후 **CNN 분류기**(R-CNN 등)에 전달.
    

---

### 📌 **정리된 파이프라인**

1. **Superpixels 생성** (Felzenszwalb segmentation)
    
2. **유사도 계산** (색상 + 질감 + 크기 + 공간 인접성)
    
3. **가장 유사한 영역 병합 → 새로운 영역 생성 → 반복**
    
4. **모든 단계에서 병합된 영역을 Region Proposal로 사용**
    

---
