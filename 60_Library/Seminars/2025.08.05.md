
[[Simple Baselines for Human Pose Estimation  and Tracking]]

## 슬라이드 2:
### 🔷 A. **Hourglass (Newell et al., 2016)**

#### 📌 핵심 구조

- 이름 그대로, 대칭적인 **encoder-decoder hourglass 구조**를 갖는 CNN
    
- 아래로 내려가며 resolution을 줄이면서 feature 추출 (encoder)
    
- 다시 위로 올라가며 resolution을 복원하고 자세 정보 결합 (decoder)
    
#### 📌 주요 특징

- Skip connection 사용 ([[U-Net Convolutional Networks for Biomedical  Image Segmentation|U-Net]]과 유사)
    
- 다양한 해상도에서 정보를 추출하고 결합 → **multi-scale context 통합**
    
- 한 블록을 반복해서 사용 가능 → **stacked hourglass**
    

#### 📌 구조 요약

```
Input
↓
Hourglass Module (downsampling + upsampling with skip connections)
↓
Conv to heatmap
↓
Repeat (optionally stacked)
↓
Output
```

---

### 🔷 B. **CPN (Chen et al., 2018)**

#### 📌 핵심 구조

- [[ResNet]] 기반의 **[[Feature Pyramid Network|Feature Pyramid Network (FPN)]]** 을 이용해 다양한 레벨의 feature 통합
    
- 이후 **[[RefineNet|RefineNet]]** 을 통해 hard keypoint를 정교화하는 **two-stage** 구조
    

#### 📌 주요 특징

- **[[GlobalNet]]**: FPN-like 구조로 multi-scale feature fusion
    
- **[[RefineNet]]**: high-resolution feature를 모아서 어려운 keypoint를 집중적으로 보정
    
- 학습 시 **[[Online Hard Keypoints Mining|Online Hard Keypoint Mining (OHKM)]]** loss 사용 (2nd stage)
    

#### 📌 구조 요약

```
Input
↓
ResNet + FPN → GlobalNet → coarse heatmap
↓
RefineNet → fine heatmap (hard keypoint 강화)
↓
Output
```

---

### 🔷 C. **Simple Baseline (Xiao et al., 2018)**

#### 📌 핵심 구조

- 복잡한 multi-stage 구조 없이, ImageNet pre-trained **[[ResNet]]** 백본만 사용
    
- 이어서 **3개의 [[Deconvolutional Networks|deconvolution block]]** 으로 해상도 복원
    
- 마지막 1×1 conv로 관절 heatmap 생성
    

#### 📌 주요 특징

- 구조가 매우 간단 (단일 블록, 단일 stage)
    
- 성능은 우수함 (high-resolution feature 덕분)
    
- 다른 방법과 달리 skip connection, refine block 없음
    

#### 📌 구조 요약

```
Input
↓
ResNet (e.g., ResNet-50)
↓
Deconv ×3 → resolution ↑
↓
1x1 Conv → heatmap
↓
Output
```

---

### 📊 3. 비교 요약 테이블

|항목|Hourglass|CPN|Simple Baseline|
|---|---|---|---|
|구조 유형|대칭형 U-Net 구조|ResNet + FPN + RefineNet|ResNet + Deconv|
|복잡도|매우 높음|높음|낮음|
|multi-scale 처리|encoder-decoder + skip|FPN 구조로 레벨 통합|없음 (단일 scale)|
|upsampling 방식|decoder + skip|deconv + concat|deconv only|
|refine 처리|가능 (stacking)|RefineNet 존재|없음|
|학습 전략|MSE loss (각 stage 합산)|OHKM + MSE|MSE|
|성능 (COCO 기준)|강력하나 무겁고 느림|매우 우수|간단하고 강력함|

---

### 🧠 핵심 차이 요약

- **Hourglass**: 가장 복잡하고 고전적인 구조. 반복 가능한 hourglass로 deep multi-scale 처리.
    
- **CPN**: multi-scale feature에 더 정교한 refinement를 추가하여 성능 극대화.
    
- **Simple Baseline**: 최소 구조로 최대 성능을 추구. ResNet + Deconv만으로도 충분히 강력함을 보임.
    

---

## 슬라이드 3

Pose Estimation은 이미지나 영상에서 **사람의 관절 위치**를 예측하는 컴퓨터 비전 기술입니다.  
사람의 머리, 어깨, 팔꿈치, 무릎 같은 관절 위치를 2차원 또는 3차원 좌표로 추정하는 것이 목적이죠.

이 기술은 **스포츠 분석, 모션 캡처, AR/VR 인터랙션, 헬스케어** 등 다양한 분야에서 활용됩니다.

---

Pose Estimation은 크게 두 가지로 나뉩니다.

첫 번째는 **2D Pose Estimation**으로, 이미지 평면 상의 관절 좌표를 (x, y)로 추정합니다.  
두 번째는 **3D Pose Estimation**으로, 깊이 z까지 포함하여 (x, y, z) 좌표로 예측합니다.

또한, 한 사람만 추정하는 **Single Person** 방식과 여러 사람을 동시에 추정하는 **Multi-Person** 방식도 있습니다.

---

자세 추정에는 대표적으로 두 가지 접근 방식이 있습니다.

첫 번째는 **Top-down 방식**입니다.  
이 방법은 먼저 이미지에서 사람을 검출한 뒤, 그 사람 각각에 대해 자세를 추정합니다.  
예를 들어, **CPN**, **Simple Baseline**, **HRNet** 같은 모델들이 대표적입니다.  
이 방식은 정확도가 높은 대신, 사람이 많아질수록 연산량이 증가합니다.

두 번째는 **Bottom-up 방식**입니다.  
이미지 전체에서 모든 관절 후보를 먼저 예측하고, 이를 사람 단위로 그룹핑하는 방식입니다.  
**OpenPose**나 **HigherHRNet** 같은 모델이 이에 해당합니다.  
이 방식은 빠르지만, 후처리 단계가 복잡하고 정확도가 떨어질 수 있습니다.

---

많은 최신 모델은 관절 좌표를 직접 예측하는 것이 아니라, **heatmap**이라는 중간 표현을 사용합니다.

각 관절에 대해 **heatmap**을 생성하는데,  
이는 특정 위치가 해당 관절일 확률을 표현한 이미지입니다.  
즉, 이미지 한 장을 입력하면, 모델은 관절별로 heatmap을 출력합니다.

학습할 때는, 정답인 관절 좌표를 중심으로 **2차원 가우시안**을 얹어 **GT heatmap**을 만듭니다.  
그리고 모델이 예측한 heatmap과 이 GT heatmap 간의 **차이(MSE Loss)** 를 줄이도록 학습합니다.

---

추론 시에는 GT heatmap 없이 이미지 하나만 입력으로 넣습니다.  
학습된 모델이 이미지로부터 예측 heatmap을 생성하고,  
각 heatmap에서 가장 값이 높은 위치, 즉 argmax를 찾아서 관절 위치를 추정합니다.

즉, **학습은 heatmap을 잘 생성하는 능력을 가르치는 과정이고**,  
**추론은 이미지 하나로 이 능력을 발휘해서 관절을 예측하는 과정**이라고 볼 수 있습니다.

---

정리하면, Pose Estimation은  
**이미지에서 사람의 관절 위치를 heatmap 기반으로 예측**하는 구조이며,  
학습은 GT heatmap과 예측 heatmap의 차이를 줄이는 방향으로 진행됩니다.  
추론 시에는 이미지 하나로 예측 heatmap을 생성하고,  
거기서 관절 좌표를 추정하는 방식으로 동작합니다.

---

## 슬라이드 4:


입력은 RGB 이미지이며, 이 이미지는 먼저 **ResNet 백본**을 통해 feature map으로 변환됩니다.  
여기서 ResNet은 일반적으로 **ResNet-50, 101, 또는 152** 중 하나를 사용하며,  
이미지의 공간 정보를 유지한 채로 **추상적인 특징을 추출하는 역할**을 합니다.

---

그 다음, 추출된 feature map은 **3개의 Deconvolution Layer**를 거치면서  
점차 해상도가 높은 feature로 복원됩니다.  
이 Deconv 단계는 단순 업샘플링이 아니라, 학습 가능한 **transpose convolution**을 사용하여  
업샘플링과 동시에 의미 있는 공간 정보를 학습할 수 있게 합니다.

---

Deconv 후에는 **1×1 Convolution**을 통해 각 joint에 대응되는 heatmap을 생성합니다.  
예를 들어 COCO 기준 17개의 관절이라면, **17채널의 heatmap**이 출력되며  
각 채널은 특정 관절이 이미지 내 어느 위치에 존재할지를 나타냅니다.

---

마지막으로, 각 heatmap에서 **가장 값이 큰 위치(argmax)** 를 찾으면,  
그 위치가 해당 관절의 좌표로 추정됩니다.

---

이처럼 Simple Baseline은 복잡한 구조 없이도  
**강력한 backbone + 단순한 upsampling + heatmap regression** 조합만으로  
우수한 성능을 달성한 대표적인 포즈 추정 모델입니다.

---

## 슬라이드 5:


이 단순한 구조에도 불구하고, Simple Baseline은 강력한 성능을 보여줍니다.  
**Table 2**를 보면, ResNet-50을 백본으로 사용했을 때

- deconv layer 수를 3개로 했을 때 가장 성능이 높았고 (AP 70.4)
    
- kernel size는 4일 때 가장 안정적이며
    
- 입력 해상도를 증가시키면 성능이 향상되는 것을 확인할 수 있습니다.  
     예를 들어, 입력 사이즈를 384×288로 키우면 **AP가 72.2**까지 상승합니다.
    

---

다음으로 **Table 3**을 보면, Simple Baseline은 기존 대표 구조인  
**8-stage Hourglass**나 **CPN(Cascaded Pyramid Network)** 와 비교해도 매우 경쟁력 있는 성능을 보여줍니다.

- CPN은 복잡한 구조와 **Online Hard Keypoints Mining(OHKM)** 기법까지 사용했지만,
    
- 동일한 입력 해상도에서 Simple Baseline은 더 높은 AP를 기록했고,
    
- 더 큰 해상도에서는 **CPN + OHKM보다도 높은 AP (72.2)** 를 달성했습니다.
    

---

즉, Simple Baseline은 복잡한 구조 없이도,  
**강력한 backbone + deconv 기반의 업샘플링 + heatmap regression**이라는 단순한 조합으로  
높은 수준의 포즈 추정 성능을 보여준다는 점에서 매우 인상적인 모델입니다.
