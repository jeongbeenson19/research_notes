
### 초록(Abstract)

객체 탐지 성능은 표준 PASCAL VOC 데이터셋에서 지난 몇 년간 정체되어 있었다. 최고 성능의 방법들은 보통 복잡한 앙상블 시스템으로, 다수의 저수준 이미지 특징과 고수준 컨텍스트를 결합한다. 본 논문에서는 평균 평균 정밀도(mean Average Precision, mAP)를 VOC 2012의 이전 최고 성능 대비 30% 이상 향상시켜 53.3%의 mAP를 달성하는 간단하고 확장 가능한 탐지 알고리즘을 제안한다. 우리의 접근법은 두 가지 주요 통찰을 결합한다: (1) 상향식(region proposals) 영역 제안에 고용량 합성곱 신경망(CNN)을 적용하여 객체를 국소화하고 분할할 수 있으며, (2) 라벨이 지정된 학습 데이터가 부족할 때, 보조 과제에 대한 지도형 사전 학습 후 도메인별 파인튜닝이 성능을 크게 향상시킨다는 것이다. 우리는 영역 제안과 CNN을 결합하기 때문에 이를 R-CNN(Regions with CNN features)이라 부른다. 또한 최근 제안된 CNN 기반 슬라이딩 윈도우 탐지기인 OverFeat와 비교하며, R-CNN이 ILSVRC2013 200-클래스 탐지 데이터셋에서 OverFeat보다 큰 폭으로 우수함을 보인다. 전체 시스템의 소스 코드는 [http://www.cs.berkeley.edu/~rbg/rcnn](http://www.cs.berkeley.edu/~rbg/rcnn)에서 제공된다.

---

### 1. 서론(Introduction)

특징은 중요하다. 지난 10년간 여러 시각 인식 작업의 진전은 상당 부분 [[SIFT]]와 [[Histogram of Oriented Gradients|HOG]]의 사용에 기반해 왔다. 하지만 PASCAL VOC 객체 탐지라는 표준 시각 인식 과제의 성능 향상은 2010~2012년 동안 더디게 진행되었으며, 주로 앙상블 시스템 구축과 기존 방법의 사소한 변형을 통해 작은 성능 향상이 이루어졌다.

SIFT와 HOG는 복잡한 세포의 방향성 히스토그램 표현으로, 영장류 시각 경로의 첫 번째 피질 영역(V1)과 대략적으로 유사하다. 그러나 인식은 여러 단계를 거친 후 발생하므로, 시각 인식에 더 유익한 계층적, 다단계 처리 과정이 있을 수 있음을 시사한다.

Fukushima의 "네오코그니트론"은 이러한 계층적이고 시프트 불변적인 패턴 인식 모델의 초기 시도였지만, 지도 학습 알고리즘이 없었다. Rumelhart 등의 연구를 기반으로 LeCun 등은 역전파를 통한 확률적 경사하강법이 CNN 학습에 효과적임을 보였다. CNN은 1990년대 널리 사용되었으나 이후 서포트 벡터 머신의 등장으로 인기가 줄었다. 2012년 Krizhevsky 등이 ILSVRC에서 큰 규모의 CNN을 학습해 ImageNet 분류 정확도를 획기적으로 향상시키면서 CNN에 대한 관심이 다시 높아졌다.

본 논문은 CNN이 PASCAL VOC에서 HOG 기반 시스템 대비 극적으로 높은 객체 탐지 성능을 달성할 수 있음을 처음으로 보여준다. 이를 위해 우리는 두 가지 문제에 집중했다: **딥 네트워크로 객체를 국소화하는 문제**와 소량의 **주석 데이터로 고용량 모델을 학습**하는 문제이다.

**이미지 분류와 달리, 탐지는 이미지 내 다수의 객체를 국소화해야 한다.** 일부 연구에서는 이를 회귀 문제로 다루지만, 동시대의 연구에 따르면 이러한 접근은 실용적으로 성능이 좋지 않다. 다른 접근은 슬라이딩 윈도우 탐지기이지만, 고층 CNN 유닛의 큰 수용 영역과 스트라이드는 슬라이딩 윈도우 방식에서 정확한 국소화에 어려움을 준다.

우리는 CNN 국소화 문제를 **"영역 기반 인식" 패러다임**을 통해 해결한다. 테스트 시, 제안된 방법은 약 2000개의 **범주 독립적 영역 제안을 생성**하고, 각 제안에서 **CNN을 통해 고정 길이 특징 벡터를 추출**하며, 클래스별 선형 **SVM으로 분류**한다. 우리는 영역의 형태와 무관하게 CNN 입력 크기를 고정하기 위해 **간단한 아핀 이미지 워핑**을 사용한다. R-CNN은 OverFeat보다 ILSVRC2013 탐지 데이터셋에서 큰 폭으로 성능이 앞선다.

두 번째 도전 과제는 라벨이 지정된 데이터가 부족하다는 점이다. 전통적으로 이는 비지도 사전학습 후 지도 파인튜닝으로 해결했으나, 우리는 ILSVRC와 같은 대규모 보조 데이터셋에 대한 지도 사전학습 후 PASCAL과 같은 소규모 데이터셋에서 도메인별 파인튜닝이 효과적임을 보였다. 이 방법은 탐지 mAP를 8%포인트 향상시킨다.

---

### 2. R-CNN을 이용한 객체 탐지(Object detection with R-CNN)

우리의 객체 탐지 시스템은 세 가지 모듈로 구성된다.  
첫 번째는 **범주 독립적(region proposals)** 영역 제안을 생성한다. 이 제안들은 탐지기에 의해 탐색될 후보 영역 집합을 정의한다.  
두 번째 모듈은 **큰 합성곱 신경망(CNN)** 으로, 각 영역에서 고정 길이의 특징 벡터를 추출한다.  
세 번째 모듈은 **클래스별 선형 SVM** 집합이다.  
이 섹션에서는 각 모듈의 설계 결정, 테스트 시 사용법, 파라미터 학습 방법, 그리고 PASCAL VOC 2010–12 및 ILSVRC2013에서의 탐지 결과를 제시한다.

---

#### 2.1. 모듈 설계(Module design)

**영역 제안(Region proposals).**  
최근의 다양한 연구들은 범주 독립적 영역 제안을 생성하는 방법을 제시하고 있다. 예로는 objectness, selective search, category-independent object proposals, constrained parametric min-cuts(CPMC), multi-scale combinatorial grouping, 그리고 CNN을 정규 간격의 정사각형 패치에 적용하는 mitotic cell 탐지 방식이 있다.  
R-CNN은 특정 영역 제안 방법에 종속적이지 않지만, 이전 탐지 연구와의 공정한 비교를 위해 **selective search**를 사용하였다.

**특징 추출(Feature extraction).**  
각 영역 제안에서 4096차원의 특징 벡터를 추출하며, 이는 Krizhevsky 등이 제안한 CNN의 Caffe 구현을 사용한다.

- 특징은 평균이 제거된 227×227 RGB 이미지를 CNN의 다섯 개의 합성곱 층과 두 개의 완전 연결 층을 통과시켜 계산한다.
    
- CNN의 아키텍처 요구사항에 따라 입력 크기는 227×227로 고정된다.
    
- 다양한 크기와 종횡비를 갖는 영역을 단순화하기 위해, **tight bounding box**를 CNN 입력 크기로 **warp(비등방성 스케일링)** 한다.
    
- warping 전, tight bounding box를 확장하여 warp 후 원래 박스 주변에 정확히 p(=16) 픽셀의 컨텍스트가 있도록 한다.  
    Figure 2는 VOC 2007 학습에서 warp된 훈련 샘플을 보여준다.
    

---

#### 2.2. 테스트 시 탐지(Test-time detection)

테스트 시, **[[Selective Search|selective search]]** 를 이용해 이미지에서 약 2000개의 영역 제안을 추출한다(모든 실험에서 "fast mode" 사용).  
각 제안을 warp한 후 CNN을 통해 특징을 계산하고, 각 클래스별 SVM으로 점수를 매긴다.  
이후, 각 클래스별로 점수가 높은 영역을 선택하면서 **[[Greedy Non-maximum Suppression|greedy non-maximum suppression(NMS)]]** 을 적용하며, IoU가 임계값 이상인 낮은 점수의 영역은 제거한다.

**실행 시간 분석(Run-time analysis).**  
효율성의 이유는 두 가지이다:

1. 모든 CNN 파라미터가 클래스 간 공유된다.
    
2. CNN이 계산하는 특징 벡터는 기존의 [[Bag-Of-Visual-Words encoding|bag-of-visual-words]] 기반 공간 피라미드 접근보다 저차원(4096 vs 360k)이다.
    

- GPU에서는 이미지당 13초, CPU에서는 53초가 걸리며, 이는 모든 클래스에 걸쳐 공유된다.
    
- 클래스별 연산은 특징-가중치의 **점곱(dot product)** 과 NMS뿐이다.
    
- 실제로 이미지당 모든 점곱은 하나의 행렬-행렬 곱으로 일괄 처리된다(대개 특징 행렬은 2000×4096, SVM 가중치 행렬은 4096×N).
    

따라서 R-CNN은 근사 기법 없이 수천 개의 클래스에도 확장 가능하다. 예를 들어 10만 개의 클래스를 처리하는 데 CPU에서 약 10초가 소요된다.

#### 해설
논문에서 말하는 "**R-CNN은 근사 기법 없이 수천 개의 클래스에도 확장 가능하다**"는 문장의 핵심은 다음 두 가지입니다:

---

##### 🔹 1. **클래스 수와 무관하게 CNN 연산 비용은 일정하다**

R-CNN에서 테스트 시 **가장 연산량이 큰 단계는 CNN forward pass**입니다.

- selective search로 약 **2000개의 region proposal**을 얻음
    
- 각 proposal을 **CNN에 통과**시켜 **4096차원 특징 벡터**로 변환
    

이 CNN 연산은 **클래스 수와 무관**하게 한번만 수행됩니다.  
즉, 2000개의 proposal만 처리하면, 10클래스이든 10만 클래스이든 **이후 연산은 feature vector에 대한 후처리**일 뿐입니다.

---

##### 🔹 2. **후처리: Feature × Weight 행렬곱으로 일괄 처리 가능**

CNN 이후에는 각 클래스에 대한 SVM 점수를 계산해야 합니다.  
이 연산은 다음과 같은 **행렬곱**으로 처리됩니다:

- feature matrix: $\mathbf{X} \in \mathbb{R}^{2000 \times 4096}$
    → 각 proposal의 CNN feature
    
- SVM weight matrix:$\mathbf{W} \in \mathbb{R}^{4096 \times C}$  
    → 클래스별 SVM weight (C = 클래스 수)
    

따라서,

$\mathbf{S} = \mathbf{X} \cdot \mathbf{W} \in \mathbb{R}^{2000 \times C}$

→ 결과적으로, 각 region proposal에 대해 각 클래스의 score가 한 번의 행렬곱으로 계산됨

💡 이 연산은 GPU에서 매우 빠르며, **10만 클래스도 병렬화로 처리 가능**

---

##### 🔹 3. **NMS는 클래스별이지만 계산량은 적음**

- 각 클래스마다 NMS(Non-Maximum Suppression)를 적용해야 하지만,
    
- 이 연산은 비교적 간단한 **정렬 및 IoU 계산 기반**의 greedy 알고리즘
    
- CNN이나 SVM보다 훨씬 가벼움
    

---

##### 🔹 4. **근사 기법이 필요 없는 이유**

다른 접근법들은 수천 개의 클래스를 처리하기 위해 근사기법(예: hashing, negative sampling 등)을 사용하지만,  
R-CNN은:

- CNN은 한 번만 계산하고
    
- SVM은 단순한 행렬곱이며
    
- NMS는 빠르게 수행되므로
    

→ 전체 시스템이 **end-to-end로 정확하게 수행 가능**하고도 **확장성이 높음**

---

##### ✅ 요약

|구성 요소|클래스 수 영향|처리 방식|
|---|---|---|
|CNN Forward Pass|❌ 영향 없음|proposal 수만큼 CNN 처리|
|SVM 점수 계산|✅ 선형 증가|행렬곱으로 병렬 처리|
|NMS|✅ 선형 증가|클래스별로 greedy 방식 처리|
|전체 시스템|✅ 확장 가능|CNN+행렬곱 구조로 효율적 확장 가능|

---

즉, R-CNN은 고정된 CNN 추출기와 선형 분류기 구조 덕분에 **10만 개의 클래스를 추가해도 CNN 재계산 없이, 연산 병렬화만으로 처리 가능**하다는 뜻입니다.  
이는 **fine-grained recognition** 또는 **open vocabulary detection**에서도 유리한 구조입니다.

---


---

#### 2.3. 학습(Training)

**지도형 사전학습(Supervised pre-training).**  
ILSVRC2012 분류 데이터셋에서 이미지 수준 라벨만을 이용해 CNN을 사전학습하였다(바운딩박스 라벨은 사용하지 않음).  
Caffe CNN 라이브러리를 사용하여 Krizhevsky 등의 성능과 유사하게 학습하였다.

**도메인별 파인튜닝(Domain-specific fine-tuning).**  
탐지 과제와 워프된 제안 윈도우 도메인에 적응시키기 위해, CNN 파라미터를 제안 영역만 사용해 추가로 **SGD**로 학습하였다.

- ImageNet 전용 1000-way 분류 레이어를 (N+1)-way 분류 레이어로 교체한다(N은 객체 클래스 수, +1은 배경).
    
- PASCAL의 경우 N=20, ILSVRC2013의 경우 N=200이다.
    
- IoU≥0.5인 제안을 양성으로, 나머지는 음성으로 간주한다.
    
- 미니배치는 양성 32, 배경 96으로 구성된다.
    

**객체 분류기(Object category classifiers).**  
SVM 학습 시, 각 클래스별로 IoU≥0.3인 영역은 양성, 그 이하인 영역은 음성으로 정의한다.

- 이 임계값은 검증 세트에서 0.3으로 최적화되었다(0.5 사용 시 mAP가 5포인트 하락).
    
- 클래스별로 하나의 선형 SVM을 학습하며, **hard negative mining** 을 사용해 빠르게 수렴한다.
    

---

#### 2.4. PASCAL VOC 2010-12 결과

모든 설계와 하이퍼파라미터는 VOC 2007에서 검증되었고, 최종 결과는 VOC 2012 train에서 파인튜닝, VOC 2012 trainval에서 SVM을 학습한 후 테스트에서 제출되었다.  
Table 1은 VOC 2010 테스트 결과를 요약한다.

- R-CNN은 같은 selective search 제안을 사용한 UVA 시스템 대비 큰 성능 향상(mAP 35.1% → 53.7%)을 보였다.
    
- VOC 2011/12 테스트에서도 유사한 성능(53.3% mAP)을 달성하였다.
    

---

#### 2.5. ILSVRC2013 탐지 결과

R-CNN은 ILSVRC2013 200-클래스 탐지 데이터셋에서도 같은 하이퍼파라미터를 사용하였다.  
Figure 3은 R-CNN이 OverFeat(24.3%)보다 크게 앞선 31.4% mAP를 기록했음을 보여준다.

---

### 3. 시각화, 소거 연구, 오류 분석 (Visualization, ablation, and modes of error)

---

#### 3.1. 학습된 특징 시각화 (Visualizing learned features)

첫 번째 합성곱 층의 필터는 직접 시각화할 수 있으며, 방향성 에지와 반대 색상(opponent colors)을 포착한다는 점에서 쉽게 이해된다. 그러나 그 이후 층을 이해하는 것은 더 어렵다. Zeiler와 Fergus는 **deconvolutional** 접근을 통해 이러한 층을 시각적으로 해석하는 방법을 제안하였다. 본 논문에서는 이를 보완하는 **비모수적(non-parametric)** 방법을 제안하며, 네트워크가 학습한 내용을 직접 보여준다.

- 특정 유닛(특징)을 선택하여 이를 하나의 객체 탐지기처럼 사용한다.
    
- 약 1천만 개의 보류된(region proposals) 영역 제안에서 해당 유닛의 활성화를 계산하고, 높은 순서대로 정렬한 뒤 NMS를 적용하고 상위 영역을 표시한다.
    
- 평균을 내지 않고 활성화가 강하게 나타나는 다양한 시각 모드를 그대로 보여줌으로써, 유닛이 계산하는 불변성(invariance)에 대한 통찰을 얻는다.
    

Figure 4에서 보듯이, 일부 유닛은 사람(1행)이나 텍스트(4행) 같은 개념과 정렬되어 있고, 다른 유닛은 점 배열(2행)이나 반사광(6행) 같은 질감과 재질 속성을 포착한다. 이는 네트워크가 클래스에 특화된 소수의 특징과 더불어 형태, 질감, 색상, 재질에 대한 분산 표현을 학습한다는 것을 시사한다.

---

#### 3.2. 소거 연구 (Ablation studies)

**파인튜닝 없이 층별 성능 (Performance layer-by-layer, without fine-tuning).**  
PASCAL VOC 2007 데이터셋에서 CNN의 마지막 세 층(pool5, fc6, fc7)의 성능을 분석하였다.

- **pool5**는 6×6×256의 맥스 풀링 출력으로, 195×195 픽셀의 수용 영역을 갖는다.
    
- **fc6**는 pool5와 완전 연결되어 있으며, 4096×9216 가중치 행렬과 편향을 사용하고, ReLU를 적용한다.
    
- **fc7**은 fc6 출력에 대해 4096×4096 가중치 행렬을 곱한 후 ReLU를 적용한다.
    

Table 2(1–3행)에 따르면, **fc7 특징이 fc6보다 일반화 성능이 떨어지며**, fc7과 fc6 모두 제거하고 pool5만 사용해도 좋은 성능을 얻을 수 있었다. CNN의 표현력 대부분은 큰 완전 연결층보다는 합성곱 층에서 기인한다.

이 결과는 **HOG처럼 CNN의 합성곱 층만을 사용해 조밀한 특징 맵을 계산**하는 것이 가능하며, pool5 위에서 DPM 같은 슬라이딩 윈도우 탐지기를 실험할 수 있음을 시사한다.

---

**파인튜닝 후 층별 성능 (Performance layer-by-layer, with fine-tuning).**  
VOC 2007 trainval에서 파인튜닝 후 결과(Table 2, 4–6행)는 **mAP가 8%포인트 향상(54.2%)** 되었다.  
개선은 pool5보다 fc6, fc7에서 더 컸으며, 이는 ImageNet에서 학습된 pool5 특징이 이미 일반적이고, 개선은 주로 도메인별 비선형 분류기 학습에서 비롯된다는 것을 의미한다.

---

**최근 특징 학습 방법과 비교 (Comparison to recent feature learning methods).**  
R-CNN은 DPM 기반 특징 학습 기법(DPM ST, DPM HSC)보다 훨씬 우수한 성능을 보였다.

- DPM ST는 스케치 토큰(Sketch Token) 확률을 HOG에 추가하여 성능을 높인다.
    
- DPM HSC는 HOG를 희소 코드 히스토그램(HSC)으로 대체한다.
    

그러나 R-CNN은 **mAP 54.2% vs DPM v5 33.7%** 로 61%의 상대적 향상을 달성했다.

---

#### 3.3. 네트워크 아키텍처 (Network architectures)

본 논문의 대부분은 Krizhevsky의 네트워크(T-Net)를 사용했으나, 아키텍처 선택은 성능에 큰 영향을 미친다.  
Table 3은 Simonyan과 Zisserman의 16층 네트워크(O-Net, VGG) 결과를 보여준다.

- O-Net은 mAP를 **58.5% → 66.0%** 로 향상시켰으나, 연산 시간이 T-Net보다 약 7배 느리다.
    

---

#### 3.4. 탐지 오류 분석 (Detection error analysis)

Hoiem 등의 탐지 분석 도구를 사용해 오류 모드를 파악하고, 파인튜닝이 이를 어떻게 바꾸는지 분석했다.  
주요 결론은 **오류의 대부분이 잘못된 위치(Localization error)** 에서 비롯된다는 점이다. 이는 CNN 특징이 배경이나 다른 객체 클래스와의 혼동보다는 위치 정밀도가 낮기 때문이다(Figure 5 참조).

---

#### 3.5. 바운딩 박스 회귀 ([[Bounding box regression|Bounding-box regression]])

오류 분석을 바탕으로, 단순한 **바운딩 박스 회귀**를 적용해 국소화 오류를 줄였다.

- pool5 특징을 이용해 제안 박스에서 실제 박스로의 변환을 예측하는 **선형 회귀 모델**을 학습했다.
    
- 이 방법은 mAP를 3~4포인트 향상시켰다(Table 1, 2, Figure 5).
    

---

#### 3.6. 정성적 결과 (Qualitative results)

Figure 8–11은 ILSVRC2013에서의 탐지 결과를 보여준다.

- 모든 이미지가 val2 세트에서 무작위로 샘플링되었으며, **정밀도 0.5 이상**의 모든 탐지를 표시했다.
    
- Figure 10과 11은 흥미로운, 예상치 못한, 혹은 인상적인 결과를 보여주는 이미지들이다.
    

---

### 4. ILSVRC2013 탐지 데이터셋 (The ILSVRC2013 detection dataset)

2장에서 우리는 ILSVRC2013 탐지 데이터셋의 결과를 제시하였다. 이 데이터셋은 PASCAL VOC보다 이질적이며, 이를 어떻게 활용할지에 대한 다양한 선택지가 존재한다. 이 섹션에서는 이러한 결정 과정을 다룬다.

---

#### 4.1. 데이터셋 개요 (Dataset overview)

ILSVRC2013 탐지 데이터셋은 다음과 같이 세 개의 세트로 나뉜다.

- **train**: 395,918장
    
- **val**: 20,121장
    
- **test**: 40,152장
    

val과 test 세트는 동일한 이미지 분포에서 추출되었으며, 장면 복잡도(객체 수, 배경 잡음, 포즈 변화 등)가 PASCAL VOC 이미지와 유사하다. 이 두 세트는 **모든 클래스의 모든 인스턴스에 대해 바운딩 박스가 완전하게 주석 처리**되어 있다.  
반면 train 세트는 ILSVRC2013 **분류 데이터셋**의 이미지 분포에서 추출되었으며, 주로 중앙에 객체 하나만 있는 이미지를 포함하고, 모든 객체가 완전히 주석 처리되지 않는다. 각 클래스별로 음성(negative) 이미지 세트가 별도로 존재하지만, 본 연구에서는 사용하지 않았다.

이러한 데이터셋 특성으로 인해 몇 가지 학습 데이터 선택이 필요하다.

- train 이미지는 완전한 주석이 없으므로 **hard negative mining**에 사용할 수 없다.
    
- train 이미지의 통계적 특성이 val/test와 다르므로 이를 학습에 사용할지 여부를 결정해야 한다.
    

본 연구에서는 **val 세트에 크게 의존**하면서 train 세트는 보조적인 양성 샘플 소스로만 사용하였다.

val 세트를 학습 및 검증용으로 나누기 위해 이를 **val1**과 **val2**로 분할하였다. 클래스 간 불균형을 최소화하기 위해 다수의 후보 분할을 생성하고, **클래스 수의 상대적 불균형이 최소인 분할**을 선택하였다(최대 불균형 약 11%, 중앙값 4%).

---

#### 4.2. 영역 제안 (Region proposals)

PASCAL과 동일한 방식으로 selective search를 사용하였으며, val1·val2·test에서 **“fast mode”** 로 실행하였다(train에서는 실행하지 않음).

- 이미지 크기에 따라 제안 수가 달라지는 문제를 해결하기 위해, **모든 이미지를 너비 500픽셀로 리사이즈**한 후 selective search를 수행하였다.
    
- val 세트에서 selective search는 이미지당 평균 2403개의 영역 제안을 생성하며, IoU 0.5 기준 **리콜 91.6%** 를 달성하였다(PASCAL의 약 98%보다 낮음).
    

---

#### 4.3. 학습 데이터 (Training data)

R-CNN의 학습에는 세 가지 과정이 필요하다.

1. CNN 파인튜닝
    
2. SVM 탐지기 학습
    
3. 바운딩 박스 회귀 학습
    

학습 데이터는 val1과 train에서 수집하였다. 각 클래스에 대해 train에서 최대 N개의 바운딩 박스를 가져와 **val1+trainN**이라는 데이터셋을 구성하였다.

- **파인튜닝**: val1+trainN에서 50k SGD 반복으로 수행하였다(NVIDIA Tesla K20에서 13시간 소요).
    
- **SVM 학습**: val1+trainN의 모든 GT 박스를 양성으로 사용하였고, val1의 5000장 무작위 샘플에서 hard negative mining을 수행하였다(전체 val1 사용 시 mAP 개선은 0.5포인트에 불과).
    
- **바운딩 박스 회귀**: val1에서 학습하였다.
    

---

#### 4.4. 검증 및 평가 (Validation and evaluation)

결과 제출 전, 위 학습 데이터로 **val2**에서 성능을 검증하였다. PASCAL에서 사용했던 모든 하이퍼파라미터를 그대로 사용하였으며, ILSVRC에 최적화된 튜닝은 진행하지 않았다.  
최종적으로 ILSVRC2013 평가 서버에 **두 번만 결과 제출**하였다.

1. 바운딩 박스 회귀 없이
    
2. 바운딩 박스 회귀 적용 후
    

---

#### 4.5. 소거 연구 (Ablation study)

Table 4는 학습 데이터 크기, 파인튜닝, 바운딩 박스 회귀의 영향을 보여준다.

- val2의 mAP는 test와 거의 일치한다.
    
- CNN을 파인튜닝하지 않고 val1만 사용하면 mAP는 20.9%에 불과하다.
    
- 학습 데이터를 **val1+trainN**으로 확장하면 mAP는 24.1%까지 상승하며, N=500과 N=1000의 차이는 거의 없다.
    
- 파인튜닝은 mAP를 **29.7%** 까지 향상시켰고, 바운딩 박스 회귀는 이를 **31.0%** 로 추가 개선하였다.
    

---

#### 4.6. [[OverFeat|OverFeat]]와의 관계 (Relationship to OverFeat)

OverFeat는 R-CNN의 특수한 형태로 볼 수 있다.

- 만약 selective search를 다중 스케일 정사각형 윈도우로 대체하고, 클래스별 바운딩 박스 회귀 대신 단일 회귀기를 사용한다면 두 시스템은 유사하다.
    
- OverFeat는 **슬라이딩 윈도우 방식**을 CNN에 완전 합성곱(convolutional) 형태로 적용하여 연산을 공유하므로, R-CNN보다 약 9배 빠르다(이미지당 2초).
    
- R-CNN의 속도를 높이는 것은 향후 과제로 남아 있으며, 이는 [[SPPNet]]과 [[Fast R-CNN]]에서 크게 개선됩니다.
    

---

### 5. 의미론적 분할 (Semantic segmentation)

영역 기반 분류(region classification)는 의미론적 분할(semantic segmentation)에서 표준적인 기법이므로, R-CNN을 간단히 수정해 PASCAL VOC 분할 과제에 적용할 수 있다. 본 연구는 최신 최고 성능의 의미론적 분할 시스템인 **O2P (second-order pooling)** [4]와 직접 비교하기 위해, 그들의 **오픈소스 프레임워크** 내에서 실험을 진행하였다.

O2P는 CPMC로 이미지당 150개의 영역 제안을 생성한 뒤, SIFT와 LBP의 확장형 특징들을 활용해 **2차 풀링(second-order pooling)** 을 수행하고, 각 클래스별로 지원 벡터 회귀(SVR)를 통해 영역 품질을 예측한다. 또한 Farabet et al.[16]은 CNN을 이용해 여러 데이터셋에서 멀티스케일 픽셀 단위 분류기를 적용하여 좋은 성능을 보였지만, PASCAL에서는 실험되지 않았다.

본 연구는 [2, 4]를 따르며 Hariharan et al.[22]이 제공한 추가 주석을 포함해 PASCAL 분할 학습 세트를 확장하였다. 설계 결정과 하이퍼파라미터는 VOC 2011 검증 세트에서 교차 검증하였으며, 최종 테스트 결과는 한 번만 평가되었다.

---

#### CNN 특징 추출 방법 (CNN features for segmentation)

CPMC 영역에서 특징을 계산하기 위해 세 가지 전략을 평가하였다. 모든 전략에서 영역 주변의 직사각형 윈도우를 **227×227** 크기로 워핑한다.

1. **full**: 영역의 형태를 무시하고 탐지와 동일하게 워핑된 전체 윈도우에서 CNN 특징을 계산한다.
    
2. **fg (foreground)**: 배경을 평균값으로 대체하여, 마스크된 전경 영역에서만 CNN 특징을 계산한다. 이는 영역의 비정사각형(shape)을 반영한다.
    
3. **full+fg**: full과 fg 특징을 단순히 **연결(concatenate)** 한다. 두 특징이 상호 보완적이라는 점을 실험으로 검증하였다.
    

---

#### VOC 2011 검증 세트 결과 (Results on VOC 2011 validation)

Table 5는 VOC 2011 검증 세트의 요약 결과를 보여준다.

- **fc6**가 항상 fc7보다 우수하다.
    
- **fg**가 full보다 약간 높은 성능을 보여, 전경 마스크가 더 강력한 신호를 제공한다.
    
- 그러나 **full+fg**는 평균 정확도 47.9%로, fg 대비 4.2% 향상되며 O2P를 소폭 능가한다.
    
- 이는 전경 특징만으로도 충분하지만, full 특징이 제공하는 **문맥(context)** 이 여전히 중요한 역할을 한다는 것을 의미한다.
    
- 20개의 SVR을 full+fg 특징으로 학습하는 데는 단일 CPU 코어에서 1시간이 소요되며, O2P의 10시간 이상에 비해 훨씬 효율적이다.
    

---

#### VOC 2011 테스트 세트 결과 (Results on VOC 2011 test)

Table 6에서 **full+fg R-CNN fc6** 방법은 두 강력한 기준선(R&P와 O2P)과 비교된다.

- 21개 클래스 중 11개에서 가장 높은 분할 정확도를 달성하였다.
    
- 전체 평균 정확도는 **47.9%** 로, O2P와 거의 동일하거나 소폭 앞선다.
    
- 추가적인 파인튜닝이 적용된다면 더 나은 성능이 기대된다.
    

---

### 6. 결론 (Conclusion)

최근 몇 년 동안 객체 탐지 성능은 정체 상태에 있었으며, 최고 성능의 시스템들은 다수의 저수준 이미지 특징과 객체 탐지기 및 장면 분류기로부터의 고수준 컨텍스트를 결합한 **복잡한 앙상블** 방식이었다.

본 논문은 **PASCAL VOC 2012**에서 이전 최고 성능 대비 **30%의 상대적 향상**을 달성하는 간단하고 확장 가능한 객체 탐지 알고리즘을 제시하였다.

---

우리는 두 가지 주요 통찰을 통해 이 성능을 달성하였다.

1. **하향식(bottom-up) 영역 제안(region proposals)에 고용량 CNN을 적용**하여 객체를 국소화하고 분할할 수 있다.
    
2. **라벨이 부족한 상황에서 대용량 CNN 학습**은, 충분한 데이터가 있는 보조 과제에 대해 **지도형 사전학습(supervised pre-training)** 을 수행한 뒤, 대상 과제에서 **도메인별 파인튜닝(domain-specific fine-tuning)** 을 적용하는 것이 매우 효과적이다.
    

이러한 학습 패러다임은 **데이터가 부족한 다양한 비전 문제**에서도 매우 유효할 것으로 추측된다.

---

우리가 이 성과를 달성한 것은, **하향식 영역 제안과 CNN이라는 고전적 컴퓨터 비전 기법과 딥러닝 기법의 결합** 덕분이다. 이는 두 접근법이 대립되는 것이 아니라, **자연스럽고 필연적인 파트너**임을 보여준다.

---

**감사의 글 (Acknowledgments)**  
이 연구는 DARPA Mind’s Eye 및 MSEE 프로그램, NSF의 IIS-0905647, IIS-1134072, IIS-1212798, MURI N000014-10-1-0933, Toyota의 지원을 받았다. 연구에 사용된 GPU는 NVIDIA의 기증을 통해 제공되었다.

---

### **부록 C. 바운딩 박스 회귀 ([[Bounding box regression|Bounding-box regression]])**

  

우리는 객체의 **정확한 위치(localization)** 성능을 향상시키기 위해 간단한 **바운딩 박스 회귀(bounding-box regression)** 단계를 사용한다.

- [[Selective Search]] 제안 영역이 클래스별 SVM으로 점수를 받은 후,
    
- **pool5 특징**을 기반으로 해당 제안 영역을 새로운 바운딩 박스로 변환하는 **클래스별 회귀기**를 학습한다.
    


이는 **DPM(deformable part model)** 에서 사용된 바운딩 박스 회귀와 유사하지만,

DPM은 **기하학적 특징**을 기반으로 회귀를 수행하는 반면, 본 연구에서는 **CNN 특징**을 기반으로 회귀를 수행한다.

---

#### **회귀 입력 구조**

  

학습 데이터는 N개의 쌍으로 구성된다:

  

$$\{ (P^i, G^i) \}_{i=1}^N$$

- $P^i = (P^i_x, P^i_y, P^i_w, P^i_h)$ : 제안 박스 P의 중심 좌표, 너비, 높이
    
- $G^i = (G^i_x, G^i_y, G^i_w, G^i_h)$ : 정답 박스 G의 동일한 파라미터
    

---

#### **회귀 함수 정의**

  

우리는 다음 네 개의 회귀 함수를 학습한다:

- 중심 이동:
    
    $$d_x(P),\quad d_y(P)$$
    
- 크기 조정:
    
    $d_w(P),\quad d_h(P)$
    

  

변환된 예측 박스 $\hat{G}$는 다음과 같이 계산된다:

  

$$\begin{aligned} \hat{G}_x &= P_w \cdot d_x(P) + P_x \\ \hat{G}_y &= P_h \cdot d_y(P) + P_y \\ \hat{G}_w &= P_w \cdot \exp(d_w(P)) \\ \hat{G}_h &= P_h \cdot \exp(d_h(P)) \end{aligned}$$

---

#### **회귀 함수 학습 방법**

  

각 함수 $d_?(P)$는 제안 영역 P의 **pool5 특징** $\phi_5$(P)에 대한 **선형 함수**로 모델링된다:

  

$$d_?(P) = w_?^\top \phi_5(P)$$

  

여기서 $w_?$는 학습 가능한 회귀 계수 벡터이다.

  

이 벡터는 다음의 **릿지 회귀(ridge regression)** 최적화 문제로 학습된다:

  

$$w_? = \arg\min_{\hat{w}?} \sum{i=1}^N (t_?^i - \hat{w}?^\top \phi_5(P^i))^2 + \lambda \|\hat{w}?\|^2$$

- $t_?$는 각 훈련 샘플의 회귀 목표값 (정답 변환 값)이다.
    

  

회귀 목표값 $t_?$는 다음과 같이 정의된다:

  

$$\begin{aligned} t_x &= (G_x - P_x)/P_w \\ t_y &= (G_y - P_y)/P_h \\ t_w &= \log(G_w / P_w) \\ t_h &= \log(G_h / P_h) \end{aligned}$$

  

이 문제는 **해가 닫힌 형태(closed-form solution)** 로 빠르게 해결 가능하다.

---

#### **구현 시 고려사항**

  

두 가지 중요한 구현 요소가 있다:

1. **정규화(regularization):**
    
    λ=1000으로 설정하였다 (검증 세트 기반).
    
2. **훈련 샘플 선택:**
    
    - 제안 박스 P가 어떤 GT 박스와도 멀리 떨어져 있다면 학습에 부적합하다.
        
    - 따라서 P가 **IoU ≥ 0.6**인 ground-truth 박스 G와 가장 큰 중첩을 가지는 경우에만 회귀 훈련 샘플로 사용하였다.
        
    - 클래스별로 독립적으로 이 과정을 반복하여 **클래스별 회귀기**를 학습하였다.
        
    

---

#### **테스트 시 적용**

- 각 제안 영역은 **한 번만 회귀 변환**된다.
    
- 반복(iterative) 적용도 실험해보았으나, 성능 향상은 없었다.
    

---

다른 부록(A, B, D, E, F, G 등)도 원하시면 번역해드릴 수 있습니다.