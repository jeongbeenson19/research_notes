
### **초록**

이 논문은 객체 탐지를 위한 빠른 영역 기반 합성곱 신경망(Fast R-CNN) 방법을 제안한다. Fast R-CNN은 이전 연구를 기반으로 하여 딥 컨볼루션 신경망을 사용해 객체 제안(object proposal)을 효율적으로 분류한다. 기존 연구와 비교했을 때, Fast R-CNN은 학습 및 테스트 속도를 향상시키고 탐지 정확도를 높이는 몇 가지 혁신적인 방법을 도입하였다. Fast R-CNN은 매우 깊은 VGG16 네트워크를 R-CNN보다 9배 빠르게 학습시키고, 테스트 시 213배 빠르며, PASCAL VOC 2012에서 더 높은 mAP를 달성한다. [[SPPNet]]과 비교하면, Fast R-CNN은 VGG16 학습 시 3배, 테스트 시 10배 더 빠르고, 더 정확하다. Fast R-CNN은 Python과 C++(Caffe 사용)로 구현되었으며, 오픈소스 MIT 라이선스 하에 공개되어 있다.

https://github.com/rbgirshick/fast-rcnn

---

### **1. 서론**


최근, 심층 합성곱 신경망(ConvNet)은 이미지 분류와 객체 탐지 정확도를 크게 향상시켰다. 이미지 분류에 비해, 객체 탐지는 더 복잡한 문제로, 이를 해결하기 위해 더 복잡한 방법이 필요하다. 이러한 복잡성 때문에 현재 접근법들은 다단계 파이프라인에서 모델을 학습시키며, 이는 느리고 비효율적이다.

탐지는 객체의 정확한 위치(localization)를 필요로 하기 때문에 두 가지 주요 문제가 발생한다. 첫째, 다수의 후보 객체 위치(“proposal”)를 처리해야 한다. 둘째, 이러한 후보들은 대략적인 위치만 제공하므로 정밀한 위치로 보정해야 한다. 이러한 문제의 해결책은 종종 속도, 정확도 또는 단순성 중 하나를 희생한다.

본 논문에서는 최신 ConvNet 기반 객체 탐지기의 학습 과정을 단순화한다. 우리는 객체 제안을 분류하고 그 공간적 위치를 보정하는 것을 동시에 학습하는 단일 단계(single-stage) 학습 알고리즘을 제안한다.

제안된 방법은 VGG16과 같은 매우 깊은 탐지 네트워크를 R-CNN보다 9배, SPPnet보다 3배 빠르게 학습시킬 수 있다. 실행 시, 객체 제안 생성 시간을 제외하고 이미지를 0.3초 만에 처리하면서 PASCAL VOC 2012에서 최고 정확도(mAP 66%, R-CNN의 62% 대비)를 달성한다.

---

### **1.1. R-CNN과 SPPnet**

  

영역 기반 합성곱 신경망 방법(R-CNN)은 딥 컨볼루션 신경망을 사용하여 객체 제안을 분류함으로써 우수한 객체 탐지 정확도를 달성한다. 그러나 R-CNN은 다음과 같은 단점이 있다.

1. **다단계 학습 파이프라인**
    
    R-CNN은 먼저 로그 손실(log loss)을 사용하여 객체 제안에 대해 ConvNet을 미세 조정(fine-tune)한다. 이후, ConvNet 특징에 SVM을 학습시킨다. 이 SVM들은 미세 조정으로 학습된 softmax 분류기를 대체하여 객체 탐지기로 작동한다. 세 번째 학습 단계에서는 바운딩 박스 회귀기를 학습시킨다.
    
2. **시간과 공간 비용이 큼**
    
    SVM과 바운딩 박스 회귀기를 학습하기 위해, 각 이미지의 모든 객체 제안에서 특징을 추출하고 이를 디스크에 저장해야 한다. VGG16과 같이 매우 깊은 네트워크의 경우, VOC07 trainval 데이터셋(5천 장 이미지)을 처리하는 데 2.5 GPU-일이 소요된다. 이 특징 데이터는 수백 GB의 저장 공간을 차지한다.
    
3. **느린 객체 탐지 속도**
    
    테스트 시, 각 테스트 이미지의 모든 객체 제안에서 특징을 추출해야 한다. VGG16을 사용할 경우, 이미지당 탐지 시간이 GPU에서 47초가 걸린다.
    

R-CNN이 느린 이유는 각 객체 제안마다 ConvNet 순전파(forward pass)를 수행하면서 계산을 공유하지 않기 때문이다. 이를 가속화하기 위해 제안된 것이 SPPnet이다. SPPnet은 입력 이미지 전체에 대해 컨볼루션 특징 맵을 계산한 뒤, 각 객체 제안을 이 특징 맵에서 추출된 벡터로 분류한다. 제안에 해당하는 영역에서 max pooling을 통해 고정 크기(e.g., 6×6) 출력을 얻고, 다양한 출력 크기를 결합하여 공간 피라미드 풀링을 구현한다.

  

SPPnet은 테스트 시 R-CNN보다 10~100배 빠르고, 학습 시 제안 특징 추출이 빨라져 3배 빠르다.

---

### **SPPnet의 한계**

  
SPPnet 역시 다음과 같은 단점이 있다.

R-CNN과 마찬가지로, 학습이 다단계 파이프라인으로 이루어진다. 특징을 추출하고, 로그 손실을 사용해 네트워크를 미세 조정한 뒤, SVM을 학습시키고, 마지막으로 바운딩 박스 회귀기를 학습시킨다. 또한, 특징을 디스크에 저장해야 한다. 그러나 R-CNN과 달리 [11]에서 제안된 SPPnet의 미세 조정 알고리즘은 공간 피라미드 풀링 이전의 컨볼루션 계층을 업데이트할 수 없다. 이러한 제한(고정된 컨볼루션 계층)은 매우 깊은 네트워크의 정확도를 제한한다.

---

### **1.2. 기여**
  

우리는 R-CNN과 SPPnet의 단점을 해결하고 속도와 정확도를 향상시키는 새로운 학습 알고리즘을 제안한다. 이를 Fast R-CNN이라 부르며, 학습과 테스트 모두 상대적으로 빠르다. Fast R-CNN의 장점은 다음과 같다.

1. R-CNN과 SPPnet보다 더 높은 탐지 품질(mAP)
    
2. 다중 작업 손실(multi-task loss)을 사용한 단일 단계 학습
    
3. 모든 네트워크 계층 업데이트 가능
    
4. 특징 캐싱을 위한 디스크 저장 불필요
    

Fast R-CNN은 Python과 C++(Caffe [13] 사용)로 작성되었으며, 오픈소스 MIT 라이선스 하에 제공된다.

https://github.com/rbgirshick/fast-rcnn

### **2. Fast R-CNN 아키텍처와 학습**

  

그림 1은 Fast R-CNN의 아키텍처를 보여준다. Fast R-CNN 네트워크는 전체 이미지와 객체 제안 집합을 입력으로 받는다. 네트워크는 먼저 여러 개의 컨볼루션(conv)과 맥스 풀링 계층을 거쳐 전체 이미지를 처리하여 컨볼루션 특징 맵(conv feature map)을 생성한다. 그 다음, 각 객체 제안마다 RoI(Region of Interest) 풀링 계층이 특징 맵으로부터 고정 길이의 특징 벡터를 추출한다. 각 특징 벡터는 일련의 완전 연결(fully connected, fc) 계층으로 전달되고, 이후 두 개의 형제 출력 계층으로 분기된다. 하나는 K개의 객체 클래스와 배경 클래스에 대한 softmax 확률을 출력하고, 다른 하나는 K개의 객체 클래스 각각에 대해 4개의 실수 값을 출력한다. 이 네 값은 해당 클래스의 보정된 바운딩 박스 위치를 나타낸다.

---

### **2.1. RoI 풀링 계층**

  

RoI 풀링 계층은 맥스 풀링을 사용하여 관심 영역 내의 특징을 H×W(예: 7×7) 크기의 작은 특징 맵으로 변환한다. 여기서 H와 W는 특정 RoI와 무관한 계층 하이퍼파라미터이다. RoI는 컨볼루션 특징 맵에서의 직사각형 창으로, 좌측 상단 좌표 (r, c)와 높이 h, 너비 w를 나타내는 4튜플 (r, c, h, w)로 정의된다.

  

RoI 맥스 풀링은 h×w RoI 창을 H×W 크기의 격자로 나누고, 각 서브 윈도우(sub-window)에서 맥스 풀링을 수행하여 출력 격자의 해당 셀에 값을 채운다. 풀링은 표준 맥스 풀링과 마찬가지로 각 채널에 독립적으로 적용된다. RoI 계층은 SPPnet [11]에서 사용된 공간 피라미드 풀링 계층의 특수한 경우로, 피라미드 레벨이 하나뿐인 형태이다. 풀링 서브 윈도우 계산은 [11]의 방법을 따른다.

### **2.2. 사전 학습된 네트워크로 초기화**

  

우리는 각각 5개의 맥스 풀링 계층과 5~13개의 컨볼루션 계층을 가진 세 개의 사전 학습된 ImageNet [4] 네트워크를 실험에 사용한다(네트워크 세부 사항은 4.1절 참조). 사전 학습된 네트워크를 Fast R-CNN 초기화에 사용할 때, 세 가지 변환 과정을 거친다.

  

첫째, 마지막 맥스 풀링 계층을 RoI 풀링 계층으로 교체하며, H와 W는 네트워크의 첫 번째 완전 연결 계층과 호환되도록 설정한다(예: VGG16의 경우 H = W = 7).

  

둘째, 원래 1000-way ImageNet 분류를 위해 학습된 네트워크의 마지막 완전 연결 계층과 softmax 계층을 제거하고, 앞서 설명한 두 개의 형제 계층(즉, K+1개의 카테고리에 대한 완전 연결 계층과 softmax, 그리고 카테고리별 바운딩 박스 회귀기)으로 교체한다.

  

셋째, 네트워크가 두 개의 입력 데이터를 받도록 수정한다. 하나는 이미지 목록이고, 다른 하나는 해당 이미지들에 포함된 RoI 목록이다.

---

### **2.3. 객체 탐지를 위한 미세 조정(Fine-tuning)**

  

네트워크의 모든 가중치를 역전파(back-propagation)로 학습시키는 것은 Fast R-CNN의 중요한 특징이다. 먼저, SPPnet이 공간 피라미드 풀링 계층 이전의 가중치를 업데이트하지 못하는 이유를 설명한다.

  

그 근본 원인은, SPP 계층을 통한 역전파가 비효율적이기 때문이다. 이는 각 학습 샘플(RoI)이 서로 다른 이미지에서 올 경우(즉, R-CNN과 SPPnet의 학습 방식) 발생한다. 각 RoI는 종종 전체 입력 이미지를 덮는 매우 큰 수용영역(receptive field)을 가지므로, 순전파 시 전체 수용영역을 처리해야 하며, 입력 크기가 커진다.

  

우리는 학습 중에도 특징 공유(feature sharing)를 활용하는 더 효율적인 학습 방법을 제안한다. Fast R-CNN 학습에서, 확률적 경사 하강법(SGD) 미니배치는 계층적으로 샘플링한다. 먼저 N개의 이미지를 샘플링하고, 각 이미지에서 R/N개의 RoI를 샘플링한다. 동일한 이미지에서 추출된 RoI들은 순전파와 역전파 과정에서 계산과 메모리를 공유한다. N을 작게 설정하면 미니배치 계산량이 줄어든다. 예를 들어, N = 2, R = 128일 때, 이 방식은 서로 다른 128개의 이미지에서 RoI를 하나씩 뽑는 기존 방법(R-CNN, SPPnet)보다 약 64배 빠르다.

  

이 방법이 느린 학습 수렴을 유발할 수 있다는 우려가 있지만, N = 2, R = 128에서도 R-CNN보다 적은 SGD 반복으로 좋은 성능을 얻었다.

  

또한 Fast R-CNN은 단일 미세 조정 단계에서 softmax 분류기와 바운딩 박스 회귀기를 동시에 최적화한다. 이는 [9, 11]처럼 분류기, SVM, 회귀기를 별도의 단계로 학습하는 방식과 다르다.

**멀티태스크 손실(Multi-task loss)**

Fast R-CNN 네트워크는 두 개의 형제 출력 계층을 가진다. 첫 번째 출력은 각 RoI에 대해 K+1개 카테고리(배경 포함)에 대한 이산 확률 분포 $p = (p_0, \dots, p_K)$ 를 제공하며, 이는 완전 연결 계층의 K+1개 출력에 대해 softmax를 적용하여 계산된다. 두 번째 출력 계층은 각 객체 클래스 k에 대해 바운딩 박스 회귀 오프셋 $t_k = (t_k^x, t_k^y, t_k^w, t_k^h)$를 출력한다. 여기서 t_k는 객체 제안(proposal)에 대한 스케일 불변 변환과 로그 공간의 높이/너비 변화를 나타낸다.

  

각 학습 RoI는 실제 클래스 u와 바운딩 박스 회귀 목표값 v를 가진다. 우리는 각 RoI에 대해 다음과 같은 멀티태스크 손실 L을 정의하여 분류와 바운딩 박스 회귀를 동시에 학습시킨다.

  

$L(p, u, t^u, v) = L_{\text{cls}}(p, u) + \lambda [u \geq 1] L_{\text{loc}}(t^u, v)$

  

여기서 $L_{\text{cls}}(p, u) = -\log p_u$는 실제 클래스 $u$에 대한 로그 손실이다. 두 번째 항 $L_{\text{loc}}$는 클래스 $u$의 바운딩 박스 회귀 목표 $v = (v_x, v_y, v_w, v_h)$와 예측 $t^u = (t_x^u, t_y^u, t_w^u, t_h^u)$ 간의 차이를 측정하며, 다음과 같이 정의된다.

  

$$L_{\text{loc}}(t^u, v) = \sum_{i \in \{x, y, w, h\}} \text{smooth}_{L_1}(t_i^u - v_i)$$

  

$$\text{smooth}_{L_1}(x) = \begin{cases} 0.5x^2 & \text{if } |x| < 1 \\ |x| - 0.5 & \text{otherwise} \end{cases}$$

  

이 $\text{smooth}_{L_1}$ 손실은 L2 손실보다 이상치에 덜 민감하다. 회귀 목표가 제한되지 않을 경우, L2 손실은 학습률 조정에 민감하여 기울기 폭발을 유발할 수 있지만, 식 (3)은 이러한 민감성을 줄여준다.

  

하이퍼파라미터 $\lambda$는 두 손실 간의 균형을 조절하며, 실험에서는 $\lambda = 1$을 사용한다.

---

**미니배치 샘플링**

미세 조정 시, 각 SGD 미니배치는 N = 2개의 이미지를 균등하게 선택하고, 각 이미지에서 64개의 RoI를 샘플링하여 총 R = 128개의 RoI를 구성한다. 이 중 25%는 IoU ≥ 0.5인 객체 제안(전경, $u \geq 1$)에서 선택하며, 나머지는 0.1 ≤ IoU < 0.5인 제안(배경, $u = 0$)에서 선택한다. 이미지 수평 뒤집기를 확률 0.5로 적용하며, 다른 데이터 증강은 사용하지 않는다.

---

**RoI 풀링 계층 역전파**

RoI 풀링 계층은 순전파 시 각 서브윈도우에서 최대값을 선택한 인덱스를 기억하며, 역전파 시 해당 인덱스에만 손실의 기울기를 전파한다. 입력 x_i에 대한 손실의 미분은 다음과 같이 계산된다.

  

$$\frac{\partial L}{\partial x_i} = \sum_r \sum_j [i = i^*(r, j)] \frac{\partial L}{\partial y_{rj}}$$

  

여기서 $i^*(r, j)$는 RoI $r$의 출력 $y_{rj}$를 생성한 입력 인덱스이다.

---

**SGD 하이퍼파라미터**

softmax 분류와 바운딩 박스 회귀의 완전 연결 계층 가중치는 평균 0, 표준편차 0.01(회귀의 경우 0.001)인 가우시안 분포로 초기화하며, 바이어스는 0으로 초기화한다. 가중치 학습률은 1, 바이어스 학습률은 2, 전역 학습률은 0.001을 사용한다. VOC07 또는 VOC12 trainval 학습 시 30k 반복 후 학습률을 0.0001로 낮추어 10k 반복을 추가 학습한다. 모멘텀은 0.9, 가중치 감쇠는 0.0005를 사용한다.

### **2.4. 스케일 불변성**

  

우리는 스케일 불변 객체 탐지를 달성하기 위해 두 가지 방법을 탐구한다.

(1) **‘무차별 대입’(brute force) 학습**

(2) **이미지 피라미드 사용**

이 두 전략은 [11]에서 사용된 접근법을 따른다.

  

무차별 대입 방식에서는 학습과 테스트 시 모든 이미지를 사전에 정의된 픽셀 크기로 처리한다. 네트워크는 학습 데이터로부터 직접 스케일 불변 객체 탐지를 학습해야 한다.

  

반면, 다중 스케일 방식에서는 이미지 피라미드를 통해 네트워크에 대략적인 스케일 불변성을 제공한다. 테스트 시, 이미지 피라미드를 사용하여 각 객체 제안의 스케일을 약 224² 픽셀 면적에 맞게 정규화한다. 다중 스케일 학습에서는 [11]과 같이 이미지를 샘플링할 때 무작위로 피라미드 스케일을 선택하여 데이터 증강을 수행한다. GPU 메모리 제한으로 인해 다중 스케일 학습은 작은 네트워크에만 적용한다.

---

## **3. Fast R-CNN 탐지**

  

Fast R-CNN 네트워크가 미세 조정된 후, 객체 탐지는 (객체 제안이 사전 계산되어 있다고 가정하면) 단순히 순전파를 수행하는 것에 가깝다. 네트워크 입력은 이미지(또는 이미지 리스트로 인코딩된 이미지 피라미드)와 점수를 매길 R개의 객체 제안 목록이다. 테스트 시 R은 보통 약 2000이지만, 45k 정도로 더 클 수도 있다. 이미지 피라미드를 사용할 경우, 각 RoI는 스케일된 RoI 면적이 224² 픽셀에 가장 가까운 스케일에 할당된다 [11].

  

각 테스트 RoI $r$에 대해, 순전파는 클래스 사후 확률 분포 $p$와 $r$에 대한 예측 바운딩 박스 오프셋 집합을 출력한다(각 K 클래스마다 고유한 보정 바운딩 박스 예측을 가짐). 우리는 각 클래스 $k$에 대해 탐지 신뢰도를 $P_r(\text{class} = k \mid r) = p_k$로 정의한다. 이후 R-CNN [9]에서 사용된 알고리즘과 설정을 따라 클래스별로 독립적으로 비최대 억제(NMS)를 수행한다.

---

### **3.1. 더 빠른 탐지를 위한 Truncated SVD**

  

전체 이미지 분류에서는 완전 연결 계층(fc)의 계산 시간이 컨볼루션 계층에 비해 작지만, 객체 탐지에서는 처리해야 할 RoI 개수가 많아 순전파 시간의 거의 절반이 완전 연결 계층 계산에 사용된다. 큰 완전 연결 계층은 Truncated SVD [5, 23]로 쉽게 가속할 수 있다.

  

이 방법은 $u \times v$ 크기의 가중치 행렬 $W$를 다음과 같이 근사 분해한다.

  

$$W \approx U \Sigma_t V^T$$

  

여기서 U는 $u \times t$ 행렬(왼쪽 특이 벡터 상위 $t$개), $\Sigma_t$는 $t \times t$ 대각 행렬(상위 $t$개의 특이값), $V$는 $v \times t$ 행렬(오른쪽 특이 벡터 상위 $t$개)이다. 이렇게 하면 매개변수 개수가 $uv$에서 $t(u+v)$로 줄어든다. $t$가 $\min(u, v)$보다 훨씬 작을 경우 절감 효과가 크다.

  

네트워크 압축 시, 원래의 완전 연결 계층을 비선형성 없이 두 개의 완전 연결 계층으로 대체한다. 첫 번째 계층은 가중치 $\Sigma_t V^T$를 사용(바이어스 없음)하고, 두 번째 계층은 U와 원래 바이어스를 사용한다. RoI 개수가 많을 때 이 방법은 좋은 속도 향상을 제공한다.

### **4. 주요 결과**

  

이 논문의 기여를 뒷받침하는 세 가지 주요 결과는 다음과 같다.

1. VOC07, 2010, 2012에서의 최신 mAP 달성
    
2. R-CNN, SPPnet 대비 빠른 학습 및 테스트 속도
    
3. VGG16에서 컨볼루션 계층을 미세 조정(fine-tune)하면 mAP 향상
    

---

### **4.1. 실험 설정**

  

우리의 실험은 온라인에서 제공되는 세 개의 사전 학습된 ImageNet 모델을 사용한다.

첫 번째는 R-CNN [9]에서 사용된 CaffeNet(사실상 AlexNet [14])으로, 이를 모델 S(Small)라 부른다.

두 번째는 [3]의 VGG CNN M 1024로, S와 깊이는 같지만 더 넓은 구조를 가진다. 이를 모델 M(Medium)이라 한다.

마지막은 [20]의 매우 깊은 VGG16 모델로, 가장 큰 모델이므로 L(Large)이라 부른다.

본 절에서는 모든 실험에서 단일 스케일 학습 및 테스트(s = 600, 세부 사항은 5.2절 참조)를 사용한다.

---

### **4.2. VOC 2010 및 2012 결과**

  

이 데이터셋에서 우리는 Fast R-CNN(FRCN)과 public leaderboard의 comp4(외부 데이터 사용) 트랙 상위 방법들을 비교한다. NUS NIN c2000 및 BabyLearning 방법에 대해서는 논문이 없고, 정확한 ConvNet 구조를 확인할 수 없지만, Network-in-Network [17] 구조의 변형을 사용한 것으로 알려져 있다. 나머지 방법은 모두 동일한 사전 학습된 VGG16으로 초기화되었다.

  

Fast R-CNN은 VOC12에서 mAP 65.7%(추가 데이터 사용 시 68.4%)로 최고 성능을 달성했다. 또한, 이 방법은 모두 느린 R-CNN 파이프라인을 기반으로 하는 다른 방법들보다 두 자릿수 배 이상 빠르다. VOC10에서는 SegDeepM [25]이 67.2%로 FRCN(66.1%)보다 높았지만, SegDeepM은 VOC12 trainval + segmentation annotation을 사용하고, R-CNN 탐지와 O2P [1] 의미 분할을 결합한 MRF 기반 기법이다. FRCN을 SegDeepM의 R-CNN 대신 사용하면 더 좋은 결과를 낼 가능성이 있다. 07++12 확장 학습 세트를 사용하면 FRCN의 mAP는 68.8%로 상승하여 SegDeepM을 능가한다.

---

### **4.3. VOC 2007 결과**

  

VOC07에서는 Fast R-CNN을 R-CNN, SPPnet과 비교한다. 모든 방법은 동일한 사전 학습된 VGG16을 사용하며 바운딩 박스 회귀를 적용한다. VGG16 SPPnet 결과는 [11]의 저자가 계산하였다. SPPnet은 학습과 테스트 모두에서 다섯 개의 스케일을 사용한다.

  

Fast R-CNN은 단일 스케일 학습 및 테스트에도 불구하고, 컨볼루션 계층을 미세 조정함으로써 SPPnet 대비 큰 mAP 향상(63.1% → 66.9%)을 보여준다. R-CNN은 mAP 66.0%를 기록했다. PASCAL에서 ‘difficult’로 표시된 예시를 제거하면 Fast R-CNN의 mAP는 68.1%로 향상된다.

### **4.4. 학습 및 테스트 시간**

  

빠른 학습 및 테스트 시간은 두 번째 주요 결과이다. 표 4는 VOC07에서 Fast R-CNN, R-CNN, SPPnet 간의 학습 시간(시간), 테스트 속도(초/이미지), mAP를 비교한 것이다.

VGG16 기준으로, Fast R-CNN은 Truncated SVD를 사용하지 않아도 R-CNN보다 146배, 사용 시 213배 빠르게 이미지를 처리한다. 학습 시간은 84시간에서 9.5시간으로 9배 단축된다. SPPnet과 비교하면, Fast R-CNN은 학습이 2.7배 빠르고(9.5시간 vs. 25.5시간), 테스트는 Truncated SVD 없이 7배, 사용 시 10배 빠르다. 또한 Fast R-CNN은 특징 캐싱을 하지 않기 때문에 수백 GB의 디스크 저장 공간이 필요 없다.

---

**Truncated SVD**

Truncated SVD는 mAP를 0.3%p 정도만 낮추면서 탐지 시간을 30% 이상 줄일 수 있다. 모델 압축 후 추가 미세 조정 없이도 가능하다. 예를 들어, VGG16의 fc6 계층(25088×4096)에서 상위 1024개의 특이값만 사용하고, fc7 계층(4096×4096)에서 상위 256개의 특이값만 사용하면, 실행 시간이 크게 줄어든다. 압축 후 다시 미세 조정하면 더 작은 mAP 손실로 추가적인 속도 향상을 얻을 수 있다.

---

### **4.5. 어떤 계층을 미세 조정할 것인가?**

  

SPPnet 논문 [11]에서 사용된 얕은 네트워크에서는 완전 연결 계층만 미세 조정해도 좋은 정확도를 얻을 수 있었다. 그러나 매우 깊은 네트워크에서는 이 결과가 유지되지 않는다고 가정하였다. 이를 검증하기 위해, Fast R-CNN에서 VGG16의 13개 컨볼루션 계층을 고정하고 완전 연결 계층만 학습시키는 실험을 수행하였다. 그 결과 mAP는 66.9%에서 61.4%로 하락했다. 이는 RoI 풀링 계층 이전의 컨볼루션 계층 학습이 깊은 네트워크에서는 중요함을 확인시켜준다.

  

모든 컨볼루션 계층을 다 학습해야 하는 것은 아니다. 작은 네트워크(S, M)에서는 conv1이 일반적이고 태스크 독립적이므로 학습 여부가 mAP에 영향을 주지 않는다. VGG16에서는 conv3_1부터 상위 계층(총 13개 중 9개)을 학습하면 충분하다. conv2_1부터 학습하면 mAP는 +0.3%p 상승하지만, 학습 시간은 1.3배(9.5시간 → 12.5시간)로 증가하고 GPU 메모리 사용량도 커진다.

따라서 본 논문에서 VGG16 실험은 모두 conv3_1 이상 계층을, S와 M 모델은 conv2 이상 계층을 미세 조정한다.


## **5. 설계 평가**

  

우리는 Fast R-CNN이 R-CNN 및 SPPnet과 비교해 어떻게 성능을 보이는지, 그리고 설계 선택들이 어떤 영향을 미치는지 이해하기 위해 일련의 실험을 수행했다. 모든 실험은 PASCAL VOC07 데이터셋에서 진행하였다.

---

### **5.1. 멀티태스크 학습이 도움이 되는가?**

  

멀티태스크 학습은 여러 단계를 순차적으로 학습시키는 파이프라인 관리가 필요 없다는 점에서 편리하다. 또한 두 작업이 동일한 표현(ConvNet)을 공유함으로써 서로 영향을 줄 수 있어 성능 향상을 기대할 수 있다 [2].

이를 검증하기 위해, 우리는 식 (1)에서 \lambda = 0으로 설정하여 분류 손실 L_{\text{cls}}만 사용하는 베이스라인 네트워크를 학습시켰다(즉, 바운딩 박스 회귀기 없음).

  

다음으로, 멀티태스크 손실(\lambda = 1)로 학습시켰지만 테스트 시 바운딩 박스 회귀를 비활성화한 네트워크를 비교했다. 이는 순수한 분류 정확도를 비교하기 위함이다.

  

모든 네트워크(S, M, L)에서 멀티태스크 학습이 단일 분류 학습 대비 +0.8~+1.1 mAP 향상을 보였다.

  

마지막으로, 단일 분류 손실로 학습한 베이스라인 모델에 바운딩 박스 회귀기를 추가하고, 나머지 네트워크 파라미터를 고정한 상태에서 L_{\text{loc}}만 학습시키는 단계별 학습(stage-wise training)을 수행했다. 이 경우 성능은 개선되었지만, 멀티태스크 학습이 여전히 더 높은 성능을 보였다.

---

### **5.2. 스케일 불변성: 무차별 대입 vs. 정교한 방식**

  

우리는 스케일 불변성을 얻기 위해 단일 스케일 학습(무차별 대입)과 다중 스케일 학습(이미지 피라미드) 전략을 비교했다.

단일 스케일에서는 가장 짧은 변의 길이가 s = 600 픽셀이 되도록 이미지를 리사이즈하되, 긴 변은 1000 픽셀로 제한하고 종횡비를 유지했다.

다중 스케일에서는 [11]의 다섯 스케일 \{480, 576, 688, 864, 1200\}을 사용하되, 긴 변을 2000 픽셀로 제한했다.

  

결과적으로, 다중 스케일은 mAP에서 약간의 향상만 제공하고 계산 비용은 크게 증가했다. VGG16 모델(L)은 구현상의 제약으로 단일 스케일만 사용했지만, mAP 66.9%를 달성하여 R-CNN(66.0%)보다 높았다. 따라서 본 논문의 나머지 실험은 모두 s = 600 단일 스케일로 진행하였다.

---

### **5.3. 더 많은 학습 데이터가 필요한가?**

  

좋은 객체 탐지기는 더 많은 학습 데이터를 제공하면 성능이 향상되어야 한다.

우리는 VOC07 trainval에 VOC12 trainval을 추가해 약 3배(총 16.5k 이미지)로 확대한 후 실험했다. 결과적으로 VOC07 테스트 mAP는 66.9%에서 70.0%로 향상되었다.

VOC10, VOC12에서도 동일하게 07 trainval, 07 test, 12 trainval을 합쳐 21.5k 이미지로 학습하면, VOC10 mAP가 66.1% → 68.8%, VOC12 mAP가 65.7% → 68.4%로 상승했다.

---

### **5.4. SVM이 softmax보다 좋은가?**

  

Fast R-CNN은 R-CNN, SPPnet처럼 학습 후 별도의 one-vs-rest SVM을 훈련하지 않고, 미세 조정에서 학습된 softmax 분류기를 그대로 사용한다. 이를 비교하기 위해, Fast R-CNN에서 SVM을 학습하고 hard negative mining을 적용한 후 mAP를 측정했다.

결과적으로 softmax가 SVM보다 0.1~0.8 mAP 높았으며, 단일 미세 조정(one-shot fine-tuning)만으로도 충분함을 보였다. 또한 softmax는 SVM과 달리 RoI 점수 계산 시 클래스 간 경쟁을 유도한다.


### **5.5. 제안(proposal)은 많을수록 좋은가?**

  

객체 탐지기는 크게 두 종류로 나눌 수 있다.

- **희소한 제안**을 사용하는 방식(예: selective search [21])
    
- **밀집한 제안**을 사용하는 방식(예: DPM [8])
    

  

희소 제안 방식에서는 제안 단계가 먼저 대부분의 후보를 제거하고, 이후 분류기가 소수의 후보만 평가한다. 이는 DPM 탐지 결과에 적용했을 때 정확도를 높이는 효과가 있었다 [21]. 우리는 이 제안-분류기 구조가 Fast R-CNN에서도 정확도를 높인다는 증거를 찾았다.

  

Selective Search의 high-quality 모드를 사용하여 이미지당 제안 개수를 1k에서 10k까지 변화시키면서 모델 M을 매번 재학습·재테스트하였다. 만약 제안이 단지 계산 효율성을 위한 역할만 한다면, 제안 수를 늘려도 mAP가 떨어지지 않아야 한다.

  

그러나 실험 결과, mAP는 제안 수가 증가함에 따라 일정 지점 이후 약간 감소했다. 이는 단순히 더 많은 제안을 넣는다고 해서 정확도가 오르지 않으며, 오히려 약간 떨어질 수도 있음을 의미한다.

  

객체 제안 품질을 평가하는 지표인 Average Recall(AR) [12]은 R-CNN 환경에서 서로 다른 제안 방법을 비교할 때 mAP와 잘 상관관계를 보이지만, 제안 수를 변화시킬 경우에는 mAP와 상관이 낮았다. 따라서 AR은 신중하게 사용해야 하며, mAP 직접 평가가 더 바람직하다. Fast R-CNN은 학습·테스트 시간이 매우 짧기 때문에 이러한 직접 평가가 실용적이다.

  

또한, 우리는 약 45k개의 밀집 박스(스케일, 위치, 종횡비 조합)를 사용해 실험했다. Selective Search 박스를 가장 IoU가 높은 밀집 박스로 교체하면 mAP는 57.7%로 1포인트만 감소했다. 그러나 Selective Search 2k 박스에 무작위로 선택한 밀집 박스를 추가하면, 제안 수가 늘어날수록 mAP가 더 크게 떨어졌고, 전부 밀집 박스만 사용하면 mAP는 52.9%로 하락했다. SVM을 사용해도 결과는 더 나빠졌다(49.3%).

---

### **5.6. MS COCO 초기 결과**

  

우리는 VGG16 기반 Fast R-CNN을 MS COCO [18] 데이터셋에 적용해 초기 성능을 측정했다. 80k 이미지 학습 세트로 240k iteration 학습한 후, “test-dev” 세트에서 평가 서버로 측정했다. PASCAL 방식 mAP는 35.9%였으며, IoU 임계값을 변화시켜 평균하는 COCO 방식 AP는 19.7%였다.


### **6. 결론**

  

이 논문은 R-CNN과 SPPnet을 개선한 간결하고 빠른 버전인 Fast R-CNN을 제안하였다.

최신 수준의 객체 탐지 성능을 보고하는 것뿐만 아니라, 새로운 통찰을 제공하기 위한 상세한 실험 결과도 제시하였다.

특히, **희소 객체 제안**이 탐지기의 품질을 향상시킬 수 있다는 점이 주목할 만하다.

이 문제는 과거에는 시간 비용이 너무 커서 깊이 탐구하기 어려웠으나, Fast R-CNN을 사용하면 실용적으로 다룰 수 있다.

물론, 밀집 박스가 희소 제안만큼 좋은 성능을 낼 수 있도록 하는 아직 발견되지 않은 기법이 존재할 수 있으며, 이러한 방법이 개발된다면 객체 탐지를 더욱 가속화하는 데 기여할 수 있을 것이다.

---

**감사의 말**

Kaiming He, Larry Zitnick, Piotr Dollár에게 유익한 토론과 격려에 감사드린다.