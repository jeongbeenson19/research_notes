### **초록(Abstract)**

기존의 심층 합성곱 신경망(CNN)은 고정된 크기의 입력 이미지를 요구한다. 이러한 제약은 임의의 크기나 비율을 가진 이미지에 대한 인식 정확도를 저하시킬 수 있으며, 이미지의 중요한 정보를 왜곡시키는 잘라내기(cropping)나 비틀기(warping) 같은 전처리 과정을 필요로 한다. 본 논문에서는 이러한 제약사항을 해결하기 위해 **공간 피라미드 풀링(Spatial Pyramid Pooling, SPP)** 이라는 새로운 풀링 전략을 제안한다. SPP는 네트워크가 입력 이미지의 크기와 상관없이 고정된 길이의 표현(representation)을 생성할 수 있게 한다. 이 SPP 계층을 기존 CNN 아키텍처에 추가한 **SPP-net**은 이미지 분류 및 객체 탐지 성능을 크게 향상시켰다. 객체 탐지에서 SPP-net은 전체 이미지에 대해 한 번만 컨볼루션 특징 맵을 계산하고, 이를 공유하여 각 후보 영역(region proposal)의 특징을 추출함으로써 [[R-CNN]] 대비 24-102배 빠른 속도를 달성하면서도 더 높은 정확도를 보였다. SPP-net은 ImageNet 2012, Pascal VOC 2007 등 주요 벤치마크에서 최상위 성능을 기록했다.

---

### **1. 서론(Introduction)**

[[Deep Residual Learning for Image Recognition|심층 컨볼루션 신경망(CNN)]]은 시각 인식 분야에서 큰 성공을 거두었지만, 대부분의 CNN 아키텍처는 고정된 크기의 입력(예: 224x224)을 요구하는 한계를 가진다. 이는 완전 연결(fully-connected) 계층이 고정된 길이의 입력 벡터를 필요로 하기 때문이다. 이러한 제약은 두 가지 문제점을 야기한다.

1.  **정보 손실**: 임의 크기의 이미지를 CNN에 입력하기 위해 잘라내거나(cropping) 비율을 무시하고 비트는(warping) 과정에서 원본 이미지의 중요한 정보가 손실될 수 있다.
2.  **비효율성**: 객체 탐지와 같이 다양한 크기의 후보 영역을 처리해야 할 때, 각 후보 영역을 고정된 크기로 변환하여 개별적으로 CNN에 입력하는 것은 엄청난 계산 중복을 유발한다. [[R-CNN]]이 바로 이러한 비효율성 문제를 겪고 있었다.

본 논문은 이러한 문제를 해결하기 위해 **공간 피라미드 풀링(SPP)**을 제안한다. SPP는 전통적인 컴퓨터 비전에서 사용되던 Bag-of-Words 모델의 아이디어를 CNN에 적용한 것으로, 컨볼루션 계층과 완전 연결 계층 사이에 위치하여 가변 크기의 특징 맵을 고정된 크기의 벡터로 변환한다.

---

### **2. 공간 피라미드 풀링(SPP) 심층 네트워크**

#### **2.1. 컨볼루션 계층과 특징 맵**

CNN의 컨볼루션 계층은 슬라이딩 윈도우 방식으로 동작하며, 입력 이미지의 크기에 제약을 받지 않고 가변 크기의 특징 맵(feature map)을 생성할 수 있다. 즉, 입력 이미지의 크기가 달라도 컨볼루션 필터는 동일하게 적용되어 공간적 정보를 유지하는 특징 맵을 출력한다. 문제는 이 특징 맵을 고정된 크기의 입력을 요구하는 완전 연결 계층에 어떻게 전달하느냐이다.

#### **2.2. 공간 피라미드 풀링 계층**

SPP 계층은 이 문제를 해결한다. SPP는 가변 크기의 특징 맵을 입력으로 받아, 여러 수준(level)의 공간적 빈(bin)으로 나누어 풀링을 수행한다.

-   예를 들어, 3-level 피라미드를 사용한다면:
    1.  **Level 1**: 특징 맵 전체를 하나의 빈으로 간주하여 max-pooling을 수행 (1x1 결과).
    2.  **Level 2**: 특징 맵을 2x2, 총 4개의 빈으로 나누어 각 빈에서 max-pooling을 수행 (2x2 결과).
    3.  **Level 3**: 특징 맵을 4x4, 총 16개의 빈으로 나누어 각 빈에서 max-pooling을 수행 (4x4 결과).

-   이렇게 각 레벨에서 얻은 풀링 결과들을 모두 연결(concatenate)하여 고정된 길이의 벡터를 생성한다. (예: 256개 채널의 특징 맵에 대해 (16+4+1) * 256 차원의 벡터)
-   이 고정 길이 벡터는 이후 완전 연결 계층의 입력으로 사용될 수 있다.

이러한 구조 덕분에 SPP-net은 입력 이미지의 크기나 종횡비에 관계없이 일관된 출력을 만들어낼 수 있다.

---

### **3. 객체 탐지를 위한 SPP-net**

[[R-CNN]]의 가장 큰 단점은 각 후보 영역마다 CNN 연산을 반복 수행하여 속도가 매우 느리다는 점이다. SPP-net은 이 문제를 혁신적으로 해결한다.

1.  **특징 맵 공유**: 전체 입력 이미지에 대해 **단 한 번만** 컨볼루션 계층을 통과시켜 전체 특징 맵(shared feature map)을 계산한다.
2.  **후보 영역 매핑**: Selective Search 등으로 찾은 각 후보 영역의 위치를 이 공유된 특징 맵에 투영(projection)한다.
3.  **SPP 적용**: 특징 맵 상에 투영된 각 영역(이제는 가변 크기의 특징 맵 조각)에 SPP 계층을 적용하여 고정 길이의 특징 벡터를 추출한다.
4.  **분류 및 회귀**: 이 특징 벡터를 완전 연결 계층과 SVM 분류기, 그리고 바운딩 박스 회귀 모델에 전달하여 최종 탐지 결과를 얻는다.

이 방식을 통해, 수천 개의 후보 영역에 대한 특징을 중복 계산 없이 매우 빠르게 추출할 수 있다. 그 결과, SPP-net은 [[R-CNN]]보다 수십에서 수백 배 빠른 테스트 속도를 달성했다.

---

### **4. 실험 및 결과**

-   **이미지 분류**: SPP-net은 ImageNet 2012 데이터셋에서 고정 크기 입력 방식의 기존 모델들보다 높은 정확도를 보였다. 특히, 다중 크기(multi-size) 학습을 통해 성능을 더욱 향상시킬 수 있었다.
-   **객체 탐지**: PASCAL VOC 2007 데이터셋에서 SPP-net은 [[R-CNN]]보다 mAP가 더 높으면서도 테스트 속도는 월등히 빨랐다. 이는 특징 맵 공유 방식의 효율성을 입증한다.

#### **SPP-net의 한계**

SPP-net은 큰 진전을 이루었지만, 여전히 몇 가지 한계를 가지고 있었다.

1.  **다단계 학습**: [[R-CNN]]과 마찬가지로 특징 추출, SVM 학습, 바운딩 박스 회귀기 학습이 분리된 다단계 파이프라인 구조를 가진다.
2.  **컨볼루션 계층 미세조정의 어려움**: SPP 계층 이전의 컨볼루션 계층 가중치를 업데이트하는 것이 비효율적이거나 불가능하여, 네트워크 전체를 end-to-end로 학습시키기 어려웠다.

이러한 한계들은 이후 [[Fast R-CNN]]에서 해결된다.

---

### **5. 결론**

본 논문은 CNN의 고정 크기 입력 제약을 해결하는 **공간 피라미드 풀링(SPP)**을 제안했다. SPP-net은 가변 크기의 이미지를 효과적으로 처리하고, 객체 탐지 시 특징 맵 공유를 통해 [[R-CNN]]의 속도 병목 현상을 극복했다. 이는 딥러닝 기반 객체 탐지기가 실시간에 가까운 성능을 낼 수 있는 가능성을 열어주었으며, [[Fast R-CNN]]과 [[Faster R-CNN]]으로 이어지는 연구의 중요한 발판이 되었다.
