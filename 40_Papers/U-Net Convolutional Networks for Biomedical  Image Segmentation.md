
### 1. Introduction

지난 2년 동안 심층 합성곱 신경망(deep convolutional networks)은 여러 시각 인식 작업에서 최신 기술(state of the art)을 능가하였다(e.g., [7,3]). 합성곱 신경망(convolutional networks)은 오래전부터 존재했지만 [8], 사용 가능한 학습 데이터셋의 크기와 네트워크의 규모가 제한되어 성과가 제한적이었다. Krizhevsky et al. [7]의 돌파구는 8개의 층과 수백만 개의 파라미터를 가진 대규모 네트워크를 ImageNet 데이터셋(100만 개의 학습 이미지)에 대해 지도 학습(supervised training)한 데 있었다. 그 이후로 더 크고 깊은 네트워크들이 학습되어왔다 [12].

합성곱 신경망의 전형적인 사용은 분류(classification) 작업이며, 이 경우 입력 이미지는 하나의 클래스 레이블로 출력된다. 그러나 특히 생의학 영상 처리(biomedical image processing)에서는 원하는 출력이 **위치 정보(localization)** 를 포함해야 한다. 즉, 각 픽셀에 클래스 레이블을 할당해야 한다. 게다가 생의학 작업에서는 수천 장의 학습 이미지를 확보하기 어렵다. 따라서 Ciresan et al. [1]은 슬라이딩 윈도우(sliding-window) 방식으로 네트워크를 학습시켜 각 픽셀 주변의 지역 영역(patch)을 입력으로 제공하여 픽셀의 클래스 레이블을 예측하였다.

이 전략은 첫째, 로컬라이제이션이 가능하며, 둘째, 패치 단위의 학습 데이터는 이미지 수보다 훨씬 많아진다는 장점이 있다. 결과적으로 이 네트워크는 ISBI 2012의 EM(전자현미경) 영상 분할 챌린지에서 큰 차이로 우승하였다.

그러나 Ciresan et al. [1]의 전략에는 두 가지 단점이 있다.

1. 각 패치마다 네트워크를 독립적으로 실행해야 하므로 매우 느리며, 패치가 중첩(overlapping)되어 많은 중복이 발생한다.
    
2. 로컬라이제이션 정확도와 문맥(context) 활용 사이의 절충(trade-off)이 필요하다. 큰 패치는 더 많은 최대 풀링 층(max-pooling layers)을 필요로 하여 로컬라이제이션 정확도를 낮추지만, 작은 패치는 충분한 문맥 정보를 보지 못한다.
    

최근 접근법 [11,4]은 다층의 특징(feature)을 함께 고려하는 분류기를 제안하여 로컬라이제이션과 문맥 활용을 동시에 가능하게 하였다.

본 논문에서는 보다 우아한 구조인 **완전 합성곱 네트워크(fully convolutional network)** [9]를 기반으로 한다. 우리는 이 구조를 수정·확장하여 소량의 학습 이미지로도 동작하며 더 정밀한 분할을 가능하게 했다(Figure 1 참조). [9]의 주요 아이디어는 일반적인 수축 네트워크(contracting network)에 업샘플링(upsampling) 연산자를 사용하는 계층을 추가하는 것이다. 이 계층들은 출력 해상도를 증가시킨다. 로컬라이제이션을 위해 수축 경로의 고해상도 특징을 업샘플링된 출력과 결합하며, 연속적인 합성곱 층이 이를 기반으로 더 정밀한 출력을 학습한다.
![[스크린샷 2025-07-22 오후 9.31.14.png]]
우리의 아키텍처의 주요 수정 사항 중 하나는 업샘플링 부분에서도 많은 수의 특징 채널(feature channels)을 유지한다는 점이다. 이를 통해 네트워크가 문맥 정보를 고해상도 계층으로 전달할 수 있다. 그 결과 확장 경로(expansive path)는 수축 경로와 대칭적이며 U자형 구조를 갖는다. 네트워크는 완전연결층을 사용하지 않고 각 합성곱의 유효(valid) 부분만 사용하므로, 입력 이미지에서 전체 문맥이 사용 가능한 픽셀만 분할 맵에 포함된다. 이 전략은 Figure 2와 같이 **타일 겹침(overlap-tile)** 방식으로 임의 크기의 큰 이미지를 원활하게 분할할 수 있게 한다. 경계 영역의 픽셀을 예측하기 위해 입력 이미지를 반사(mirroring)하여 부족한 문맥을 보완한다. 이 타일링 전략은 큰 이미지를 처리할 때 필수적이며, 그렇지 않으면 GPU 메모리에 의해 해상도가 제한된다.

또한 학습 데이터가 매우 적기 때문에, 우리는 가용한 학습 이미지를 탄성 변형(elastic deformations)으로 증강하여 과도한 데이터 증강(data augmentation)을 수행하였다. 이를 통해 주석 이미지에서 직접 변형 사례를 보지 않고도 이러한 변형에 대한 불변성(invariance)을 학습할 수 있다. 이는 생의학 영상 분할에서 특히 중요하며, 조직에서 변형이 가장 흔한 변화이며 현실적인 변형은 효율적으로 시뮬레이션할 수 있다. 데이터 증강의 가치에 대해서는 Dosovitskiy et al. [2]가 비지도 특징 학습 범위에서 보여주었다.

많은 세포 분할 작업에서의 또 다른 도전은 동일 클래스의 접촉하는 물체를 분리하는 것이다(Figure 3 참조). 이를 위해 우리는 접촉하는 세포를 구분하는 배경 레이블에 큰 가중치를 부여하는 **가중 손실(weighted loss)** 을 제안하였다.

이 네트워크는 다양한 생의학 분할 문제에 적용 가능하다. 본 논문에서는 ISBI 2012 EM 스택의 신경 구조 분할에서 Ciresan et al. [1]의 네트워크를 능가하는 결과를 보여주며, ISBI cell tracking challenge 2015의 2D 전송광 데이터셋에서도 큰 격차로 우승하였다.

### 2. Network Architecture

네트워크 아키텍처는 Figure 1에 제시되어 있으며, **수축 경로(contracting path)**(왼쪽)와 **확장 경로(expansive path)**(오른쪽)로 구성된다.

- **수축 경로**는 전형적인 합성곱 신경망 구조를 따른다. 3x3 **무패딩(unpadded) 합성곱** 2회, 각 합성곱 뒤의 ReLU 활성화 함수, 그리고 스트라이드 2의 2x2 **최대 풀링(max pooling)** 연산이 반복된다. 다운샘플링이 일어날 때마다 특징 채널(feature channel)의 수는 2배가 된다.
    
- **확장 경로**의 각 단계는
    
    1. 특징 맵의 업샘플링,
        
    2. 특징 채널 수를 절반으로 줄이는 2x2 **업-합성곱(up-convolution)**,
        
    3. 수축 경로의 잘린(cropped) 특징 맵과의 **연결(concatenation)**,
        
    4. 두 번의 3x3 합성곱과 각 합성곱 뒤의 ReLU  
        로 이루어진다.  
        크롭(cropping)은 각 합성곱에서 경계 픽셀이 손실되기 때문에 필요하다.
        
- 마지막 층에서는 **1x1 합성곱**을 사용해 각 64차원 특징 벡터를 원하는 클래스 수로 매핑한다. 전체 네트워크는 총 **23개의 합성곱 층**을 가진다.
    
- 출력 분할 맵의 원활한 타일링(Seamless tiling, Figure 2 참조)을 위해서는, 모든 2x2 최대 풀링 연산이 **짝수 x, y 크기의 층**에 적용되도록 입력 타일 크기를 선택하는 것이 중요하다.

### 3. Training

입력 이미지와 해당 분할 맵을 이용해 **Caffe [6]의 확률적 경사 하강법(SGD)** 으로 네트워크를 학습한다.  
무패딩 합성곱을 사용하기 때문에 출력 이미지는 입력보다 일정한 폭의 경계가 작다. **GPU 메모리를 최대한 활용**하고 오버헤드를 최소화하기 위해, 큰 배치 크기보다는 **큰 입력 타일**을 선호하며, 배치는 **단일 이미지**로 줄인다. 따라서 **높은 모멘텀(0.99)** 을 사용하여 이전에 본 많은 학습 샘플들이 현재 최적화 단계의 업데이트를 결정하도록 한다.

- **에너지 함수**는 최종 특징 맵의 **픽셀 단위 소프트맥스(soft-max)** 와 **크로스 엔트로피 손실**로 계산된다.  
    소프트맥스는 다음과 같이 정의된다.
    

$$
p_k(x) = \frac{\exp(a_k(x))}{\sum_{k'=1}^K \exp(a_{k'}(x))}
$$
여기서 $a_k(x)$는 위치 $x \in \Omega$의 k번째 채널 활성화이며, $K$는 클래스 수이다. $p_k(x)$는 $k$번째 클래스의 확률 근사값이며, 최대 활성화된 $k$에서는 1에 가깝고 나머지는 0에 가깝다.

- **크로스 엔트로피 손실**은 다음과 같다.
    

$$
E = \sum_{x \in \Omega} w(x) \log(p_{\ell(x)}(x)) \tag{1}
$$
여기서 $\ell : \Omega \to \{1, ..., K\}$는 각 픽셀의 실제 레이블이며, $w : \Omega \to \mathbb{R}$은 특정 픽셀의 중요도를 높이기 위해 도입한 **가중치 맵(weight map)** 이다.

#### 가중치 맵(Weight Map)

- 각 정답 분할 맵마다 클래스 간 픽셀 빈도를 보정하고, 접촉하는 세포 사이의 **분리 경계(separation border)** 를 학습하도록 가중치를 사전에 계산한다(Figure 3c, d 참조).
    
- 분리 경계는 형태학적 연산(morphological operations)으로 계산하며, 가중치는 다음과 같다.
    

$$
w(x) = w_c(x) + w_0 \cdot \exp\left(-\frac{(d_1(x) + d_2(x))^2}{2\sigma^2}\right) \tag{2}
$$
여기서  
$w_c : \Omega \to \mathbb{R}$은 클래스 빈도 균형을 위한 가중치,  
$d_1(x)$은 가장 가까운 세포 경계까지의 거리,  
$d_2(x)$은 두 번째로 가까운 세포 경계까지의 거리이다.  
실험에서는 $w_0 = 10$, $\sigma \approx 5$ 픽셀로 설정하였다.

#### 가중치 초기화

깊은 네트워크에서는 적절한 **가중치 초기화**가 매우 중요하다. 그렇지 않으면 일부 경로는 과도한 활성화를 보이는 반면 다른 경로는 거의 기여하지 않는다.  
이상적으로 초기 가중치는 각 특징 맵이 **단위 분산**을 갖도록 설정해야 한다.  
본 아키텍처(합성곱- ReLU 교차 구조)에서는 **표준편차**를

$$
\sqrt{\frac{2}{N}}
$$
으로 하는 가우시안 분포에서 가중치를 초기화한다(He et al. [5]). 여기서 N은 한 뉴런의 입력 노드 수이다(예: 3x3 합성곱과 이전 층의 64채널 → $N = 9 \cdot 64 = 576$).

### 3.1 Data Augmentation

데이터 증강은 학습 샘플이 적을 때 네트워크가 원하는 **불변성(invariance)** 과 **강건성(robustness)** 을 학습하는 데 필수적이다.

생물학적 현미경 이미지의 경우, 주로 **이동 및 회전 불변성**과 **변형 및 명암값 변화에 대한 강건성**이 필요하다.  
특히, **무작위 탄성 변형(random elastic deformations)** 이 매우 적은 수의 주석 이미지로 분할 네트워크를 학습하는 핵심 개념이다.

- **탄성 변형 생성 방법**
    
    - 3x3의 조밀한(coarse) 격자에서 무작위 변위 벡터를 생성한다.
        
    - 변위는 **표준편차 10픽셀의 가우시안 분포**에서 샘플링한다.
        
    - 이후 **bicubic 보간**을 사용해 각 픽셀의 변위를 계산한다.
        
- **추가 증강 기법**
    
    - 수축 경로의 마지막 부분에 삽입된 **드롭아웃(drop-out) 층**이 암묵적으로 데이터 증강 효과를 제공한다.

### 4. Experiments

우리는 U-Net을 세 가지 서로 다른 분할 작업에 적용하였다.

#### 4.1 EM 영상의 신경 구조 분할

첫 번째 작업은 전자현미경(EM) 영상에서의 **신경 구조 분할**이다(Figure 2 참조).  
이 데이터셋은 ISBI 2012에서 시작된 **EM segmentation challenge [14]** 의 일환으로, 아직도 새로운 기여를 받고 있다.

- **데이터**
    
    - 초파리(Drosophila) 1령 유충의 복측 신경 코드(VNC)를 촬영한 **직렬 절편 전자현미경 이미지** 30장(각 512×512 픽셀)
        
    - 각 이미지에는 **세포(흰색)** 와 **세포막(검은색)** 에 대한 완전 주석된 정답 분할 맵이 포함됨
        
    - 테스트 세트는 공개되어 있으나 분할 맵은 비공개이며, 예측된 막의 확률 맵을 주최 측에 제출하면 평가 가능
        
    - 평가는 10개의 임계값으로 확률 맵을 이진화하여 **워핑 에러(warping error)**, **Rand error**, **픽셀 에러(pixel error)** 를 계산
        
- **결과**
    
    - U-Net은 입력 데이터의 7가지 회전 버전을 평균하여 추가 전처리·후처리 없이 **워핑 에러 0.0003529**, **Rand error 0.0382**를 달성(새로운 최고 성능, Table 1 참조)
        
    - 이전 최고 성능(Ciresan et al. [1]): 워핑 에러 0.000420, Rand error 0.0504
        
    - Rand error에서 U-Net보다 약간 더 좋은 성능을 보인 알고리즘들은 모두 **특정 데이터셋에 특화된 후처리(post-processing)** 를 적용한 것
        

---

#### 4.2 ISBI Cell Tracking Challenge – 세포 분할

또한 우리는 U-Net을 **광학 현미경 이미지의 세포 분할**에도 적용하였다(ISBI Cell Tracking Challenge 2014 & 2015 [10,13]).

- **PhC-U373 데이터셋**
    
    - **상분리 위상차 현미경(phase contrast microscopy)** 으로 촬영된 **Glioblastoma-astrocytoma U373 세포**
        
    - 35장의 부분 주석된 학습 이미지
        
    - **평균 IOU(intersection over union)**: 92%
        
    - 이는 2위 알고리즘(83%)보다 상당히 우수한 성능(Table 2 참조)
        
- **DIC-HeLa 데이터셋**
    
    - **차등 간섭 대비(DIC) 현미경**으로 촬영된 **HeLa 세포**
        
    - 20장의 부분 주석된 학습 이미지
        
    - **평균 IOU**: 77.5%
        
    - 2위 알고리즘(46%) 대비 큰 차이로 우승(Figure 3, Figure 4 참조)

### 5. Conclusion

U-Net 아키텍처는 매우 다양한 **생의학 영상 분할** 작업에서 뛰어난 성능을 보였다.  
특히 **탄성 변형(elastic deformations)을 활용한 데이터 증강** 덕분에 **아주 적은 수의 주석 이미지**만으로도 학습이 가능하며, 학습 시간 또한 **NVIDIA Titan GPU(6 GB)** 에서 **약 10시간**으로 합리적인 수준이다.

또한, 우리는 **Caffe[6] 기반의 전체 구현과 학습된 네트워크**를 공개하였다.  
저자들은 U-Net 아키텍처가 앞으로 더 많은 다양한 작업에도 쉽게 적용될 수 있을 것이라고 확신한다.

---
